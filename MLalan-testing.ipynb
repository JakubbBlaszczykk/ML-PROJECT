{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f17d71ce",
   "metadata": {},
   "source": [
    "# DATA LOADING + DATA CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =======================\n",
    "#  Azure URLs\n",
    "# =======================\n",
    "URL_NAME_BASICS    = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_104122_UTC/name.basics.tsv.gz\"\n",
    "URL_TITLE_AKAS     = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_104546_UTC/title.akas.tsv.gz\"\n",
    "URL_TITLE_BASICS   = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_104810_UTC/title.basics.tsv.gz\"\n",
    "URL_TITLE_CREW     = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_104937_UTC/title.crew.tsv.gz\"\n",
    "URL_TITLE_EPISODE  = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_105103_UTC/title.episode.tsv.gz\"\n",
    "URL_TITLE_PRINC    = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_105225_UTC/title.principals.tsv.gz\"\n",
    "URL_TITLE_RATINGS  = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_105430_UTC/title.ratings.tsv.gz\"\n",
    "\n",
    "# =======================\n",
    "#  Start DuckDB connection\n",
    "# =======================\n",
    "# Connect to an in-memory database or specify a file: database='imdb_merge.duckdb'\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "start_time = time.time()\n",
    "print(\" Starting IMDb data merge using DuckDB...\\n\")\n",
    "\n",
    "# =======================\n",
    "#  Stage progress tracker\n",
    "# =======================\n",
    "stages = [\n",
    "    \"Registering IMDb files\",\n",
    "    \"Joining basics + ratings + crew + episode\",\n",
    "    \"Joining akas\",\n",
    "    \"Joining principals\",\n",
    "    \"Joining name.basics\",\n",
    "    \"Exporting to Parquet\"\n",
    "]\n",
    "progress = tqdm(total=len(stages), desc=\"Progress\", ncols=80, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}')\n",
    "\n",
    "# =======================\n",
    "#  Register TSV.GZ files as virtual tables\n",
    "# =======================\n",
    "# DuckDB can read directly from HTTPS URLs and handle compressed files.\n",
    "# 'auto_detect=True' helps with schema, but we specify key params.\n",
    "base_read_csv = \"SELECT * FROM read_csv('{}', delim='\\\\t', nullstr='\\\\\\\\N', header=True, compression='gzip', auto_detect=True, parallel=True)\"\n",
    "\n",
    "con.execute(f\"CREATE OR REPLACE VIEW name_basics AS {base_read_csv.format(URL_NAME_BASICS)};\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW title_basics AS {base_read_csv.format(URL_TITLE_BASICS)};\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW title_ratings AS {base_read_csv.format(URL_TITLE_RATINGS)};\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW title_crew AS {base_read_csv.format(URL_TITLE_CREW)};\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW title_episode AS {base_read_csv.format(URL_TITLE_EPISODE)};\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW title_akas AS {base_read_csv.format(URL_TITLE_AKAS)};\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW title_principals AS {base_read_csv.format(URL_TITLE_PRINC)};\")\n",
    "\n",
    "progress.update(1)\n",
    "progress.set_description(stages[1])\n",
    "\n",
    "# =======================\n",
    "#  Perform joins step by step\n",
    "# =======================\n",
    "# This step-by-step materialization helps manage memory\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE merged_core AS\n",
    "SELECT *\n",
    "FROM title_basics b\n",
    "LEFT JOIN title_ratings r USING (tconst)\n",
    "LEFT JOIN title_crew c USING (tconst)\n",
    "LEFT JOIN title_episode e USING (tconst);\n",
    "\"\"\")\n",
    "progress.update(1)\n",
    "progress.set_description(stages[2])\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE merged_with_akas AS\n",
    "SELECT *\n",
    "FROM merged_core mc\n",
    "LEFT JOIN title_akas a ON mc.tconst = a.titleId;\n",
    "\"\"\")\n",
    "progress.update(1)\n",
    "progress.set_description(stages[3])\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE merged_with_principals AS\n",
    "SELECT *\n",
    "FROM merged_with_akas ma\n",
    "LEFT JOIN title_principals p ON ma.tconst = p.tconst;\n",
    "\"\"\")\n",
    "progress.update(1)\n",
    "progress.set_description(stages[4])\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE imdb_final AS\n",
    "SELECT *\n",
    "FROM merged_with_principals mp\n",
    "LEFT JOIN name_basics n ON mp.nconst = n.nconst;\n",
    "\"\"\")\n",
    "progress.update(1)\n",
    "progress.set_description(stages[5])\n",
    "\n",
    "# =======================\n",
    "#  Export to Parquet\n",
    "# =======================\n",
    "con.execute(\"\"\"\n",
    "COPY (SELECT * FROM imdb_final) \n",
    "TO 'imdb_merged_duckdb.parquet' (FORMAT PARQUET, COMPRESSION 'SNAPPY', ROW_GROUP_SIZE 100000);\n",
    "\"\"\")\n",
    "progress.update(1)\n",
    "progress.close()\n",
    "\n",
    "# =======================\n",
    "#  Clean up\n",
    "# =======================\n",
    "con.close()\n",
    "elapsed = (time.time() - start_time)\n",
    "print(f\"\\n✅ Done! Merged dataset saved as imdb_merged_duckdb.parquet (Elapsed: {elapsed:.2f} seconds)\")\n",
    "print(\"   Reload it fast with: pd.read_parquet('imdb_merged_duckdb.parquet')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0231dfdc",
   "metadata": {},
   "source": [
    "# Brief Summary of Our Whole Process of Merging IMDb Datasets\n",
    "\n",
    "## 1. GOAL\n",
    "Merge all datasets into one master table, so that:\n",
    "- Each row contains all information for a title (or exploded rows for multiple actors or alternate titles).\n",
    "- Later, We can clean and analyze the data.\n",
    "\n",
    "## 2. CHALLENGES\n",
    "- Some files (`title.akas` and `title.principals`) are very large (5–10 GB).\n",
    "- Merging everything at once may use too much RAM and crash the computer.\n",
    "- Many rows in `akas` and `principals` may not be relevant to the titles in the main dataset.\n",
    "\n",
    "## 3. APPROACH (CHUNKED MERGE)\n",
    "1. Load small datasets into memory first: `title.basics`, `title.ratings`, `title.crew`, `title.episode`, `name.basics`.\n",
    "2. Merge small datasets on `tconst` → master table with one row per title.\n",
    "3. Build a set of relevant titles (`tconst_set`) for fast filtering.\n",
    "4. Process big datasets (`title.akas` and `title.principals`) in chunks (~300k rows), filter by `tconst_set`, then merge.\n",
    "5. Merge `name.basics` to attach actor/director info using `nconst`.\n",
    "6. Save final dataset (Parquet recommended, CSV optional).\n",
    "\n",
    "## 4. HOW MERGING WORKS\n",
    "- `df_left.merge(df_right, left_on=\"colA\", right_on=\"colB\", how=\"left\")`:\n",
    "  - Left table = main/master table.\n",
    "  - Right table = extra info (ratings, actors, alternate titles).\n",
    "  - `how=\"left\"` keeps all rows from the left table; missing matches → NaN.\n",
    "\n",
    "## 5. ADVANTAGES OF CHUNKED MERGE\n",
    "- Memory-efficient – never load huge tables fully.\n",
    "- Fast filtering – only process rows relevant to `tconst_set`.\n",
    "- Safe – reduces risk of crashing.\n",
    "- Complete – preserves all relevant info, including multiple actors and alternate titles.\n",
    "\n",
    "## 6. NOTES AFTER MERGE\n",
    "- Multiple rows per title are normal:\n",
    "  - One row per actor (`title.principals`).\n",
    "  - One row per alternate title (`title.akas`).\n",
    "- Later during data cleaning, you can:\n",
    "  - Deduplicate rows.\n",
    "  - Aggregate actors or alternate titles into lists.\n",
    "  - Normalize genres or other fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5197ce",
   "metadata": {},
   "source": [
    "# First steps on Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f745da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset you created in the first script\n",
    "try:\n",
    "    df_raw = pd.read_parquet('imdb_merged_chunked.parquet')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'imdb_merged_chunked.parquet' not found.\")\n",
    "    print(\"Please run your 'imdb_chunked_merge_azure.py' script first.\")\n",
    "    # As a fallback, create a dummy dataframe for the script to run\n",
    "    df_raw = pd.DataFrame({\n",
    "        'tconst': ['tt000001'], 'primaryTitle': ['Movie Title'], 'startYear': [2000],\n",
    "        'averageRating': [8.0], 'numVotes': [100], 'genres': ['Action,Drama'],\n",
    "        'directors': ['nm000001'], 'writers': ['nm000002'], 'parentTconst': [np.nan],\n",
    "        'seasonNumber': [np.nan], 'episodeNumber': [np.nan], 'titleId': ['tt000001'],\n",
    "        'ordering_x': [1], 'title': ['movie title'], 'region': ['US'], 'language': ['en'],\n",
    "        'isOriginalTitle': [0], 'ordering_y': [1], 'nconst': ['nm000003'],\n",
    "        'category': ['actor'], 'job': [np.nan], 'characters': ['[\"Lead Role\"]'],\n",
    "        'primaryName': ['Actor Name'], 'birthYear': [1980], 'deathYear': [np.nan]\n",
    "    })\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(\"1. DATA INFO\")\n",
    "print(\"=\"*30)\n",
    "# Use verbose=True to see all columns\n",
    "df_raw.info(verbose=True, memory_usage='deep')\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"2. MISSING VALUES (Top 20)\")\n",
    "print(\"=\"*30)\n",
    "missing_values = df_raw.isnull().sum()\n",
    "missing_percent = (missing_values / len(df_raw) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'count': missing_values, 'percent': missing_percent})\n",
    "print(missing_df[missing_df['count'] > 0].sort_values(by='count', ascending=False).head(20))\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"3. DUPLICATE ROWS\")\n",
    "print(\"=\"*30)\n",
    "num_dupes = df_raw.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_dupes}\")\n",
    "# Note: Duplicates might be expected if a title has multiple actors/akas\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"4. CATEGORICAL CARDINALITY (Top 20)\")\n",
    "print(\"=\"*30)\n",
    "categorical_cols = df_raw.select_dtypes(include=['object', 'category']).columns\n",
    "cardinality = {col: df_raw[col].nunique() for col in categorical_cols}\n",
    "print(\"Number of unique values in categorical columns:\")\n",
    "# Sort by cardinality (highest first) to find problematic columns\n",
    "sorted_cardinality = sorted(cardinality.items(), key=lambda x: x[1], reverse=True)\n",
    "for col, count in sorted_cardinality[:20]:\n",
    "    print(f\"{col}: {count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"5. NUMERIC DISTRIBUTION\")\n",
    "print(\"=\"*30)\n",
    "# This helps spot outliers and skew\n",
    "numeric_cols = df_raw.select_dtypes(include=np.number).columns\n",
    "print(df_raw[numeric_cols].describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae67b8b",
   "metadata": {},
   "source": [
    "# Key transformation\n",
    "1. Drop Columns (DropColumnTransformer)\n",
    "- t removes ordering_akas, ordering_principal, attributes, and job\n",
    "- These are redundant keys or ordering columns from the original files that are not needed after merging on tconst and nconst. They add noise and increase memory usage\n",
    "\n",
    "2. Standardize Strings (StringCleaner)\n",
    "- Lowercases and strips whitespace from free-text columns like primaryTitle and primaryName\n",
    "- Ensures consistency. \"The Matrix\", \" the matrix \", and \"the matrix\" become identical (\"the matrix\"), which prevents the model from treating them as different categories.\n",
    "\n",
    "3. Clean List-Strings (ListStringCleaner)\n",
    "- Handles comma-separated columns like genres and directors. It turns 'Action, Adventure' into 'action,adventure'\n",
    "- This is crucial for feature engineering.\n",
    "\n",
    "4. Parse JSON-Strings (JSONStringParser)\n",
    "- Specifically targets the characters column, which is often a messy string like '[\"Walter White\", \"Heisenberg\"]'. It parses this into a clean, comma-separated string: 'walter white,heisenberg'\n",
    "- This \"unpacks\" the valuable information (who an actor played) from a format that is otherwise unusable.\n",
    "\n",
    "5. Impute Missing Values (SimpleImputer)\n",
    "* Fills in missing data.\n",
    "- For numeric our strategy is \"median\", so we fill missing values with median \n",
    "- For categorical ones our strategy is \"constant\", we fill each null value with string \"unknown\"\n",
    "\n",
    "!!!CustomOutlierRemoval is included, but separated from the main pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68d34b",
   "metadata": {},
   "source": [
    "# Cleaning done with pandas (initial approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ada34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ==================================\n",
    "# 1. DEFINE CUSTOM TRANSFORMERS\n",
    "# ==================================\n",
    "\n",
    "class DropColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Drops specified columns.\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns, axis=1, errors='ignore')\n",
    "\n",
    "class StringCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Strips whitespace, lowercases, and converts to string.\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X_transformed.columns:\n",
    "                X_transformed[col] = X_transformed[col].astype(str).str.strip().str.lower()\n",
    "        return X_transformed\n",
    "\n",
    "class ListStringCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Cleans comma-separated list-strings (e.g., genres).\"\"\"\n",
    "    def __init__(self, columns, separator=','):\n",
    "        self.columns = columns\n",
    "        self.separator = separator\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X_transformed.columns:\n",
    "                X_transformed[col] = X_transformed[col].fillna('')\n",
    "                X_transformed[col] = X_transformed[col].apply(\n",
    "                    lambda s: self.separator.join(\n",
    "                        [item.strip().lower() for item in str(s).split(self.separator)]\n",
    "                    ) if s else ''\n",
    "                )\n",
    "        return X_transformed\n",
    "\n",
    "class JSONStringParser(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Parses columns containing string representations of JSON lists.\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def _parse(self, item):\n",
    "        if pd.isna(item):\n",
    "            return ''  # ⭐️⭐️⭐️ THE FIX IS HERE ⭐️⭐️⭐️ (Was '[]', now '\"\"')\n",
    "        try:\n",
    "            parsed_list = json.loads(item)\n",
    "            if isinstance(parsed_list, list):\n",
    "                return ','.join([str(i).strip().lower() for i in parsed_list])\n",
    "            return ''\n",
    "        except (json.JSONDecodeError, TypeError, SyntaxError):\n",
    "            # Handle cases where it's not a valid JSON list (e.g., just \"ActorName\")\n",
    "            return str(item).strip().lower()\n",
    "            \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X_transformed.columns:\n",
    "                X_transformed[col] = X_transformed[col].apply(self._parse)\n",
    "        return X_transformed\n",
    "\n",
    "class CustomOutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Removes rows based on Z-score of specified numeric columns.\"\"\"\n",
    "    def __init__(self, columns, threshold=3):\n",
    "        self.threshold = threshold\n",
    "        self.columns = columns\n",
    "        self._outliers = None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        valid_cols = [col for col in self.columns if col in X.columns and pd.api.types.is_numeric_dtype(X[col])]\n",
    "        if not valid_cols:\n",
    "            print(\"Warning: No valid numeric columns found for outlier removal.\")\n",
    "            return X_transformed\n",
    "        \n",
    "        # Ensure NaNs are handled before zscore\n",
    "        z_scores = np.abs(stats.zscore(X_transformed[valid_cols], nan_policy='omit'))\n",
    "        \n",
    "        # Fill NaNs in z_scores with 0 (so they aren't considered outliers)\n",
    "        z_scores_filled = np.nan_to_num(z_scores, nan=0)\n",
    "        \n",
    "        mask = (z_scores_filled < self.threshold).all(axis=1)\n",
    "        self._outliers = X_transformed[~mask]\n",
    "        return X_transformed[mask]\n",
    "    @property\n",
    "    def outliers(self):\n",
    "        return self._outliers\n",
    "\n",
    "# ==================================\n",
    "# 2. DEFINE COLUMN GROUPS\n",
    "# ==================================\n",
    "\n",
    "# Columns to remove: Redundant IDs, low-value, or messy\n",
    "DROP_COLS = [\n",
    "    'ordering_akas', \n",
    "    'ordering_principal',\n",
    "    'attributes',\n",
    "    'job'\n",
    "]\n",
    "\n",
    "# Simple strings to clean (lowercase, strip)\n",
    "CLEAN_STRING_COLS = [\n",
    "    'primaryTitle',\n",
    "    'originalTitle',\n",
    "    'title_akas', # Renamed from 'title'\n",
    "    'primaryName'\n",
    "]\n",
    "\n",
    "# Numeric columns to impute (with median)\n",
    "NUMERIC_IMPUTE_COLS = [\n",
    "    'startYear',\n",
    "    'endYear',\n",
    "    'runtimeMinutes',\n",
    "    'averageRating',\n",
    "    'numVotes',\n",
    "    'seasonNumber',\n",
    "    'episodeNumber',\n",
    "    'birthYear',\n",
    "    'deathYear'\n",
    "]\n",
    "\n",
    "# Categorical columns to impute (with 'unknown')\n",
    "CATEGORICAL_IMPUTE_COLS = [\n",
    "    'titleType',\n",
    "    'isAdult',\n",
    "    'region',\n",
    "    'language',\n",
    "    'types',\n",
    "    'category'\n",
    "]\n",
    "\n",
    "# Comma-separated list-strings\n",
    "LIST_STRING_COLS = [\n",
    "    'genres',\n",
    "    'directors',\n",
    "    'writers',\n",
    "    'primaryProfession',\n",
    "    'knownForTitles'\n",
    "]\n",
    "\n",
    "# JSON-like list-strings\n",
    "JSON_STRING_COLS = [\n",
    "    'characters'\n",
    "]\n",
    "\n",
    "# Numeric columns to check for outliers\n",
    "OUTLIER_COLS = [\n",
    "    'runtimeMinutes',\n",
    "    'numVotes',\n",
    "    'averageRating',\n",
    "    'startYear'\n",
    "]\n",
    "\n",
    "# ==================================\n",
    "# 3. BUILD THE CLEANING PIPELINE\n",
    "# ==================================\n",
    "\n",
    "print(\"Building cleaning pipeline...\")\n",
    "\n",
    "# Define imputers\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "categorical_imputer = SimpleImputer(strategy='constant', fill_value='unknown')\n",
    "\n",
    "# Create the main cleaning pipeline\n",
    "cleaning_pipeline = Pipeline(steps=[\n",
    "    ('drop_cols', DropColumnTransformer(columns=DROP_COLS)),\n",
    "    ('clean_strings', StringCleaner(columns=CLEAN_STRING_COLS)),\n",
    "    ('clean_list_strings', ListStringCleaner(columns=LIST_STRING_COLS)),\n",
    "    ('parse_json_strings', JSONStringParser(columns=JSON_STRING_COLS)),\n",
    "    \n",
    "    ('impute_features', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num_impute', numeric_imputer, NUMERIC_IMPUTE_COLS),\n",
    "            ('cat_impute', categorical_imputer, CATEGORICAL_IMPUTE_COLS)\n",
    "        ],\n",
    "        remainder='passthrough' # Keep all other columns\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Define the outlier remover separately\n",
    "outlier_remover = CustomOutlierRemover(columns=OUTLIER_COLS, threshold=3)\n",
    "\n",
    "# ==================================\n",
    "# 4. EXECUTE THE PIPELINE\n",
    "# ==================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"1. APPLYING MAIN CLEANING PIPELINE\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# We assume 'df' is already loaded in memory\n",
    "print(f\"Shape before cleaning: {df.shape}\")\n",
    "\n",
    "# --- Reconstruct the DataFrame after pipeline ---\n",
    "\n",
    "# Get the list of columns that remain *after* the ColumnTransformer\n",
    "# 1. Get columns *before* the imputer step\n",
    "temp_df = cleaning_pipeline.named_steps['parse_json_strings'].transform(\n",
    "    cleaning_pipeline.named_steps['clean_list_strings'].transform(\n",
    "        cleaning_pipeline.named_steps['clean_strings'].transform(\n",
    "            cleaning_pipeline.named_steps['drop_cols'].transform(df)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Get the 'remainder' columns\n",
    "imputed_cols = NUMERIC_IMPUTE_COLS + CATEGORICAL_IMPUTE_COLS\n",
    "remainder_cols = [col for col in temp_df.columns if col not in imputed_cols]\n",
    "\n",
    "# 3. Define the final column order\n",
    "final_cols = NUMERIC_IMPUTE_COLS + CATEGORICAL_IMPUTE_COLS + remainder_cols\n",
    "\n",
    "# 4. Apply the pipeline\n",
    "df_cleaned_data = cleaning_pipeline.fit_transform(df)\n",
    "df_cleaned = pd.DataFrame(df_cleaned_data, columns=final_cols)\n",
    "\n",
    "# 5. Convert numeric columns back to numeric types\n",
    "for col in NUMERIC_IMPUTE_COLS:\n",
    "    df_cleaned[col] = pd.to_numeric(df_cleaned[col])\n",
    "# Convert isAdult back to numeric/int\n",
    "if 'isAdult' in df_cleaned.columns:\n",
    "    df_cleaned['isAdult'] = pd.to_numeric(df_cleaned['isAdult'])\n",
    "\n",
    "print(f\"Shape after cleaning: {df_cleaned.shape}\")\n",
    "\n",
    "# ==================================\n",
    "# 5. ⭐️ SAVE THE CLEANED FILE FOR COLLEAGUES ⭐️\n",
    "# ==================================\n",
    "OUTPUT_FILE_PARQUET = 'imdb_cleaned_for_colleagues.parquet'\n",
    "print(f\"\\nSaving cleaned data to {OUTPUT_FILE_PARQUET}...\")\n",
    "df_cleaned.to_parquet(OUTPUT_FILE_PARQUET, index=False)\n",
    "print(\"✅ Save complete.\")\n",
    "# ==================================\n",
    "\n",
    "print(\"\\nCleaned Data Info:\")\n",
    "df_cleaned.info(memory_usage='deep')\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"2. APPLYING OUTLIER REMOVAL\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "df_no_outliers = outlier_remover.fit_transform(df_cleaned)\n",
    "\n",
    "print(f\"Shape before outlier removal: {df_cleaned.shape}\")\n",
    "print(f\"Shape after outlier removal:  {df_no_outliers.shape}\")\n",
    "print(f\"Removed {len(outlier_remover.outliers)} outlier rows.\")\n",
    "\n",
    "print(\"\\n✅ Full cleaning pipeline complete! File saved for colleagues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c900dcf",
   "metadata": {},
   "source": [
    "# Filtered DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "#main part\n",
    "url = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_105430_UTC/imdb_merged_duckdb.parquet\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "print(\"Loading data into pandas DataFrame using DuckDB...\")\n",
    "\n",
    "# ⭐️ This is the line you need to add:\n",
    "df = con.execute(f\"SELECT * FROM read_parquet('{url}')\").df()\n",
    "\n",
    "con.close()\n",
    "\n",
    "print(\"✅ Data loaded successfully.\")\n",
    "print(df.head())\n",
    "print(f\"DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e402f",
   "metadata": {},
   "source": [
    "# Code for the general overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "294eef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               column     type      total        nulls  null_pct  min_val  \\\n",
      "0              tconst  varchar  465811724          0.0      0.00      NaN   \n",
      "1           titleType  varchar  465811724          0.0      0.00      NaN   \n",
      "2        primaryTitle  varchar  465811724          0.0      0.00      NaN   \n",
      "3       originalTitle  varchar  465811724          0.0      0.00      NaN   \n",
      "4             isAdult   bigint  465811724          0.0      0.00      0.0   \n",
      "5           startYear   bigint  465811724   65894855.0     14.15   1874.0   \n",
      "6             endYear  varchar  465811724  458488696.0     98.43      NaN   \n",
      "7      runtimeMinutes   bigint  465811724  269538145.0     57.86      0.0   \n",
      "8              genres  varchar  465811724   16246770.0      3.49      NaN   \n",
      "9       averageRating   double  465811724  367425094.0     78.88      1.0   \n",
      "10           numVotes   bigint  465811724  367425094.0     78.88      5.0   \n",
      "11          directors  varchar  465811724  102012828.0     21.90      NaN   \n",
      "12            writers  varchar  465811724  112687062.0     24.19      NaN   \n",
      "13       parentTconst  varchar  465811724  101166474.0     21.72      NaN   \n",
      "14       seasonNumber   bigint  465811724  136575677.0     29.32      1.0   \n",
      "15      episodeNumber   bigint  465811724  136575677.0     29.32      0.0   \n",
      "16            titleId  varchar  465811724      59793.0      0.01      NaN   \n",
      "17           ordering   bigint  465811724      59793.0      0.01      1.0   \n",
      "18              title  varchar  465811724      59793.0      0.01      NaN   \n",
      "19             region  varchar  465811724   97667814.0     20.97      NaN   \n",
      "20           language  varchar  465811724  166901244.0     35.83      NaN   \n",
      "21              types  varchar  465811724  308428025.0     66.21      NaN   \n",
      "22         attributes  varchar  465811724  461729427.0     99.12      NaN   \n",
      "23    isOriginalTitle   bigint  465811724      59793.0      0.01      0.0   \n",
      "24           tconst_1  varchar  465811724    4076907.0      0.88      NaN   \n",
      "25         ordering_1   bigint  465811724    4076907.0      0.88      1.0   \n",
      "26             nconst  varchar  465811724    4076907.0      0.88      NaN   \n",
      "27           category  varchar  465811724    4076907.0      0.88      NaN   \n",
      "28                job  varchar  465811724  379682851.0     81.51      NaN   \n",
      "29         characters  varchar  465811724  242832221.0     52.13      NaN   \n",
      "30           nconst_1  varchar  465811724    4130750.0      0.89      NaN   \n",
      "31        primaryName  varchar  465811724    4130750.0      0.89      NaN   \n",
      "32          birthYear   bigint  465811724  266957431.0     57.31      4.0   \n",
      "33          deathYear   bigint  465811724  407662889.0     87.52     17.0   \n",
      "34  primaryProfession  varchar  465811724   19586026.0      4.20      NaN   \n",
      "35     knownForTitles  varchar  465811724    4462847.0      0.96      NaN   \n",
      "\n",
      "      max_val      mean_val  median_val  distinct_vals  \\\n",
      "0         NaN           NaN         NaN       11993523   \n",
      "1         NaN           NaN         NaN             11   \n",
      "2         NaN           NaN         NaN        5393741   \n",
      "3         NaN           NaN         NaN        5420470   \n",
      "4         1.0      0.007206         0.0              2   \n",
      "5      2115.0   2005.709074      2012.0            153   \n",
      "6         NaN           NaN         NaN             98   \n",
      "7   3692080.0     57.698560        45.0            974   \n",
      "8         NaN           NaN         NaN           2364   \n",
      "9        10.0      6.607314         6.7             91   \n",
      "10  3111175.0  16255.571975       182.0          23831   \n",
      "11        NaN           NaN         NaN         980178   \n",
      "12        NaN           NaN         NaN        1457099   \n",
      "13        NaN           NaN         NaN         227318   \n",
      "14     2024.0      2.670104         1.0            326   \n",
      "15    91334.0    594.466106        81.0          15845   \n",
      "16        NaN           NaN         NaN       11984050   \n",
      "17      251.0      4.849548         4.0            251   \n",
      "18        NaN           NaN         NaN        7650111   \n",
      "19        NaN           NaN         NaN            249   \n",
      "20        NaN           NaN         NaN            110   \n",
      "21        NaN           NaN         NaN             23   \n",
      "22        NaN           NaN         NaN            184   \n",
      "23        1.0      0.207151         0.0              2   \n",
      "24        NaN           NaN         NaN       10823900   \n",
      "25       75.0      7.244164         6.0             75   \n",
      "26        NaN           NaN         NaN        6852309   \n",
      "27        NaN           NaN         NaN             13   \n",
      "28        NaN           NaN         NaN          45518   \n",
      "29        NaN           NaN         NaN        4372575   \n",
      "30        NaN           NaN         NaN        6845023   \n",
      "31        NaN           NaN         NaN        5664836   \n",
      "32     2025.0   1956.282206      1961.0            485   \n",
      "33     2025.0   2001.534219      2007.0            429   \n",
      "34        NaN           NaN         NaN          19833   \n",
      "35        NaN           NaN         NaN        4346918   \n",
      "\n",
      "                                             examples  \n",
      "0                     tt0102859, tt0102860, tt0102861  \n",
      "1                                 video, movie, movie  \n",
      "2                 Science Crazed, Scissors, Scorchers  \n",
      "3                 Science Crazed, Scissors, Scorchers  \n",
      "4                                             0, 0, 0  \n",
      "5                                    1991, 1991, 1991  \n",
      "6                                    1991, 1991, 1991  \n",
      "7                                         83, 105, 81  \n",
      "8        Comedy,Horror, Horror,Thriller, Comedy,Drama  \n",
      "9                                       2.6, 5.1, 5.5  \n",
      "10                                     181, 3467, 723  \n",
      "11                    nm0842833, nm0208342, nm0063581  \n",
      "12          nm0842833, nm0783679,nm0208342, nm0063581  \n",
      "13                    tt1338457, tt1338457, tt1369618  \n",
      "14                                            1, 1, 1  \n",
      "15                                   2843, 2842, 2844  \n",
      "16                    tt0102859, tt0102860, tt0102861  \n",
      "17                                            4, 9, 9  \n",
      "18  Science Crazed, Fenêtre sur crime, American Co...  \n",
      "19                                         CA, FR, DE  \n",
      "20                                         ru, ja, en  \n",
      "21              imdbDisplay, imdbDisplay, imdbDisplay  \n",
      "22  complete title, new title, alternative transli...  \n",
      "23                                            0, 0, 0  \n",
      "24                    tt0102859, tt0102860, tt0102861  \n",
      "25                                         17, 22, 19  \n",
      "26                    nm0842833, nm0824175, nm0251679  \n",
      "27   editor, production_designer, production_designer  \n",
      "28              production_designer, editor, producer  \n",
      "29         [\"Aldrovandi\"], [\"W.B. Springer\"], [\"Cop\"]  \n",
      "30                    nm0842833, nm0824175, nm0251679  \n",
      "31        Ron Switzer, Craig Stearns, Bill Eigenbrodt  \n",
      "32                                   1942, 1944, 1939  \n",
      "33                                   2025, 2005, 2014  \n",
      "34  director,writer,editor, production_designer,ar...  \n",
      "35  tt0102859, tt0110475,tt0208003,tt2543312,tt183...  \n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# 1️⃣ Register your parquet file as a view\n",
    "PARQUET_URL = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_105430_UTC/imdb_merged_duckdb.parquet\"\n",
    "TABLE = \"imdb_raw\"\n",
    "\n",
    "con.execute(f\"CREATE OR REPLACE VIEW {TABLE} AS SELECT * FROM read_parquet('{PARQUET_URL}');\")\n",
    "\n",
    "# 2️⃣ Get all columns & types\n",
    "cols_info = con.execute(f\"DESCRIBE {TABLE};\").fetchdf()\n",
    "\n",
    "stats_list = []\n",
    "\n",
    "# 3️⃣ Loop through columns and compute stats\n",
    "for _, row in cols_info.iterrows():\n",
    "    col = row[\"column_name\"]\n",
    "    coltype = row[\"column_type\"].lower()\n",
    "\n",
    "    if any(t in coltype for t in [\"int\", \"double\", \"decimal\", \"float\", \"numeric\"]):\n",
    "        q = f\"\"\"\n",
    "        SELECT\n",
    "            '{col}' AS column,\n",
    "            '{coltype}' AS type,\n",
    "            COUNT(*) AS total,\n",
    "            SUM(CASE WHEN {col} IS NULL THEN 1 ELSE 0 END) AS nulls,\n",
    "            ROUND(100.0 * SUM(CASE WHEN {col} IS NULL THEN 1 ELSE 0 END) / COUNT(*), 2) AS null_pct,\n",
    "            MIN({col}) AS min_val,\n",
    "            MAX({col}) AS max_val,\n",
    "            AVG({col}) AS mean_val,\n",
    "            MEDIAN({col}) AS median_val,\n",
    "            COUNT(DISTINCT {col}) AS distinct_vals\n",
    "        FROM {TABLE};\n",
    "        \"\"\"\n",
    "    else:\n",
    "        q = f\"\"\"\n",
    "        SELECT\n",
    "            '{col}' AS column,\n",
    "            '{coltype}' AS type,\n",
    "            COUNT(*) AS total,\n",
    "            SUM(CASE WHEN {col} IS NULL THEN 1 ELSE 0 END) AS nulls,\n",
    "            ROUND(100.0 * SUM(CASE WHEN {col} IS NULL THEN 1 ELSE 0 END) / COUNT(*), 2) AS null_pct,\n",
    "            NULL AS min_val,\n",
    "            NULL AS max_val,\n",
    "            NULL AS mean_val,\n",
    "            NULL AS median_val,\n",
    "            COUNT(DISTINCT {col}) AS distinct_vals\n",
    "        FROM {TABLE};\n",
    "        \"\"\"\n",
    "\n",
    "    stats_list.append(con.execute(q).fetchdf())\n",
    "\n",
    "# 4️⃣ Concatenate results into a single DataFrame\n",
    "overview = pd.concat(stats_list, ignore_index=True)\n",
    "\n",
    "# 5️⃣ Add sample values (a few examples from each column)\n",
    "sample_values = {}\n",
    "for col in cols_info[\"column_name\"]:\n",
    "    try:\n",
    "        val = con.execute(f\"SELECT {col} FROM {TABLE} WHERE {col} IS NOT NULL LIMIT 3;\").fetchdf()\n",
    "        sample_values[col] = ', '.join(map(str, val[col].tolist()))\n",
    "    except Exception:\n",
    "        sample_values[col] = \"error\"\n",
    "\n",
    "overview[\"examples\"] = overview[\"column\"].map(sample_values)\n",
    "\n",
    "# 6️⃣ Display neatly\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print(overview)\n",
    "\n",
    "# Optional: Save to file for later analysis\n",
    "overview.to_parquet(\"imdb_column_overview.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d1348",
   "metadata": {},
   "source": [
    "# IMDB merged dataset — column-by-column review & proposed actions\n",
    "\n",
    "\n",
    "| Column | Current null % | Potential decision | Rationale |\n",
    "|---|---:|---|---|\n",
    "| `tconst` | 0.00% | **KEEP (id)** | Primary id — keep. |\n",
    "| `titleType` | 0.00% | **KEEP (as categorical)** | Useful metadata. Fill `'unknown'` if missing (none). |\n",
    "| `primaryTitle` / `originalTitle` | 0.00% | **KEEP** | Clean strings (lower/strip). |\n",
    "| `isAdult` | 0.00% | **KEEP** | convert to 0/1 integer. |\n",
    "| `startYear` | 14.15% | **KEEP + IMPUTE (median)** | Year missing ~14% — impute median (or mode) if you need no nulls. If time-series needed, consider keeping NULLs. |\n",
    "| `endYear` | 98.43% | **DROP** ✅ | Vast majority missing — not useful. |\n",
    "| `runtimeMinutes` | 57.86% | **KEEP + INVESTIGATE** (recommended: median imputation) | Very many missing; check distribution. If you need runtime, impute median; else consider dropping if mostly missing for your use-case. |\n",
    "| `genres` | 3.49% | **KEEP** | Normalize lists; fill `'unknown'` when missing. |\n",
    "| `averageRating` | 78.88% | **DROP** (recommended) or **KEEP+IMPUTE(median)** (alternative) | High missingness — dropping is defensible. If rating is core to your analysis, keep and impute median but be aware of bias. |\n",
    "| `numVotes` | 78.88% | **DROP** (recommended) or **KEEP+IMPUTE(median)** | Highly skewed and mostly missing; if you need it, consider log-transform + median impute. |\n",
    "| `directors` / `writers` | 21.90% / 24.19% | **KEEP** | Normalize lists, fill `'unknown'`. |\n",
    "| `parentTconst` | 21.72% | **KEEP (fill 'unknown')** | Might be useful for episodes; fill unknown if you must remove nulls. |\n",
    "| `seasonNumber` / `episodeNumber` | 29.32% | **KEEP (fill 0 or median)** | For non-episodic rows these are naturally NULL. Fill with 0 if you prefer no nulls. |\n",
    "| `titleId` / `ordering` / `title` (akas) | very small | **KEEP** | Keep/clean. |\n",
    "| `region` / `language` / `types` | 20–66% | **KEEP + CLEAN** | For `types` large missingness — check values; fill `'unknown'`. |\n",
    "| `attributes` | 99.12% | **DROP** ✅ | Nearly entirely empty — drop. |\n",
    "| `isOriginalTitle` | 0.01% | **KEEP** | Clean/convert. |\n",
    "| `nconst`, `nconst_1`, `tconst_1`, `ordering_1` | small nulls | **KEEP** | Fill `'unknown'` for ids or 0 for ordering if necessary. |\n",
    "| `category` | 0.88% | **KEEP** | Fill `'unknown'`. |\n",
    "| `job` | 81.51% | **DROP** ✅ | Very sparse — drop unless you need it. |\n",
    "| `characters` | 52.13% | **KEEP** (clean & empty-string default) | Strip JSON-like brackets and quotes; keep as CSV string, fill `''` if missing. |\n",
    "| `primaryName` / `birthYear` / `deathYear` | birthYear 57.31% / deathYear 87.52% | **birthYear: keep+impute; deathYear: DROP** | deathYear mostly missing — drop. BirthYear could be useful (impute median or keep NULLs). |\n",
    "| `primaryProfession` | 4.20% | **KEEP** | Fill `'unknown'`. |\n",
    "| `knownForTitles` | 0.96% | **KEEP** | Fill `'unknown'` if missing. |\n",
    "\n",
    "---\n",
    "\n",
    "## My recommended action (DEFAULT)\n",
    "- **Drop**: `endYear`, `deathYear`, `attributes`, `job`.  \n",
    "- **Drop or keep w/ caution** (you choose): `averageRating`, `numVotes` — recommended to drop because ~79% missing; if ratings are central to your analysis, keep and **impute median** (not mean).  \n",
    "- **Impute numeric columns with median** (if you want ZERO NULLS): `startYear`, `runtimeMinutes`, `seasonNumber`, `episodeNumber`, `birthYear` (choose median or domain default).  \n",
    "- **Impute strings** with `'unknown'`.  \n",
    "- **characters** → clean JSON-like strings and default to `''` if missing.  \n",
    "- After you accept/reject these, run the code cell to create a final cleaned parquet and an overview report.\n",
    "\n",
    "---\n",
    "\n",
    "If you accept the DEFAULT plan above, run the code cell that follows. If you want different choices for `averageRating` / `numVotes` / `runtimeMinutes` (e.g., keep-and-impute vs drop), edit the code comments before running.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96758e1",
   "metadata": {},
   "source": [
    "### 🔍 Rethinking the Null-Handling Strategy (Second Review)\n",
    "\n",
    "After reviewing the column-wise null percentages and my initial cleaning plan, I realized that some of the earlier imputation choices might not make much sense for how the IMDb dataset is structured. Below is a more careful and logical re-evaluation of each case:\n",
    "\n",
    "---\n",
    "\n",
    "#### 🎬 `startYear`  \n",
    "If the dataset is at least somewhat chronologically ordered, taking the **previous non-null value** might actually preserve the temporal continuity between nearby entries — which could make more sense than throwing in a random median year.  \n",
    "However, this assumption depends on whether the data is sorted by title or ID, so this needs to be tested before implementation.\n",
    "\n",
    "---\n",
    "\n",
    "#### ⏱️ `runtimeMinutes`\n",
    "Here we have around **60% nulls**, so filling them with a median value could seriously distort the data distribution.  \n",
    "A better approach might be:\n",
    "- either **set nulls to 0**, indicating “unknown runtime,”  \n",
    "- or introduce a **new category like `'unknown_runtime'`** if we later decide to treat it as categorical.  \n",
    "For now, setting it to `0` (meaning *missing or undefined duration*) feels more realistic.\n",
    "\n",
    "---\n",
    "\n",
    "#### 📺 `seasonNumber` and `episodeNumber`\n",
    "Median imputation doesn’t make any sense here because the majority of titles are just standalone movies — not part of any TV show.  \n",
    "Using median would just create weird pseudo-seasons.  \n",
    "So the cleanest fix is to **set missing values to `0`**, clearly meaning “not applicable.”\n",
    "\n",
    "---\n",
    "\n",
    "#### 👶 `birthYear`\n",
    "About **57% nulls**, which is quite a lot.  \n",
    "The median year might not represent anything meaningful (imagine all unknown actors suddenly born in 1975).  \n",
    "Possible alternatives:\n",
    "- Keep it but fill missing values with `0` (or a placeholder like `'unknown'` if treated as text),  \n",
    "- Or drop it entirely if we don’t plan to analyze by actor age.  \n",
    "I lean toward **keeping it** (with a numeric placeholder like `0`) for now, just to preserve structure.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🗓️ `endYear`\n",
    "Originally, I wanted to drop `endYear` as well because it had **over 98% nulls**,  \n",
    "but on second thought, it might still serve as an indicator of whether a show or title is still running.  \n",
    "Instead of removing it completely, I’ll **replace nulls with `0`** to represent *“not ended”* or *“still active”*.  \n",
    "That way, the column can be treated as a binary-like numeric field (`0` = still ongoing, otherwise actual end year).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b5c64",
   "metadata": {},
   "source": [
    "# After reconsidering the cleaning, here we will proceed with 2nd cleaning approach using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a0f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe: 100000 rows, 36 columns\n",
      "Zero-filling columns: ['runtimeMinutes', 'seasonNumber', 'episodeNumber', 'birthYear', 'endYear', 'averageRating', 'numVotes', 'deathYear']\n",
      "Running LeftoverNullFiller...\n",
      "✅ Cleaning done: 100000 rows, 35 columns\n",
      "\n",
      "--- Null count per column ---\n",
      "🎉 All null values have been handled! 🎉\n",
      "\n",
      "--- Sample rows (post-cleaning) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>...</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "      <th>nconst_1</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>tt12528796</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.333</td>\n",
       "      <td>episode #1.333</td>\n",
       "      <td>0</td>\n",
       "      <td>1938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm5426054</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm5426054</td>\n",
       "      <td>venu arvind</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor,director,writer</td>\n",
       "      <td>tt13439272,tt0242256,tt0318993,tt2923826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80184</th>\n",
       "      <td>tt10540368</td>\n",
       "      <td>short</td>\n",
       "      <td>jellyfish</td>\n",
       "      <td>jellyfish</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>short</td>\n",
       "      <td>9.2</td>\n",
       "      <td>...</td>\n",
       "      <td>nm10792182</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>caretaker</td>\n",
       "      <td>nm10792182</td>\n",
       "      <td>trinidad asensio robles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt10540368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>tt21104030</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #2.15</td>\n",
       "      <td>episode #2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>family,reality-tv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1101797</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>self - contestant</td>\n",
       "      <td>nm1101797</td>\n",
       "      <td>duncan james</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor,soundtrack,archive_footage</td>\n",
       "      <td>tt0112004,tt1470249,tt12870980,tt12115616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76699</th>\n",
       "      <td>tt5907054</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.3</td>\n",
       "      <td>episode #1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0199858</td>\n",
       "      <td>writer</td>\n",
       "      <td>adaptation</td>\n",
       "      <td></td>\n",
       "      <td>nm0199858</td>\n",
       "      <td>carmen daniels</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>writer</td>\n",
       "      <td>tt0211796,tt0229914,tt5378734,tt0214376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92991</th>\n",
       "      <td>tt14400866</td>\n",
       "      <td>tvseries</td>\n",
       "      <td>a couple of cuckoos</td>\n",
       "      <td>kakkou no iinazuke</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>animation,comedy,romance</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>nm5928101</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>additional voices</td>\n",
       "      <td>nm5928101</td>\n",
       "      <td>jacob eiseman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt3398540,tt10981954,tt9671916,tt13375866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76434</th>\n",
       "      <td>tt0928280</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>privilege</td>\n",
       "      <td>privilege</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>crime,drama,mystery</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0454236</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ernest foley</td>\n",
       "      <td>nm0454236</td>\n",
       "      <td>richard kind</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor,writer,soundtrack</td>\n",
       "      <td>tt2096673,tt1024648,tt1019452,tt0120623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84004</th>\n",
       "      <td>tt22643502</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 11 october 2022</td>\n",
       "      <td>episode dated 11 october 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>news</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm4834517</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>self - fox business correspondent</td>\n",
       "      <td>nm4834517</td>\n",
       "      <td>lauren simonetti</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>archive_footage</td>\n",
       "      <td>tt9130562,tt3230032,tt7483086,tt3776548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80917</th>\n",
       "      <td>tt0352167</td>\n",
       "      <td>movie</td>\n",
       "      <td>amme bhagavathi</td>\n",
       "      <td>amme bhagavathi</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0530818</td>\n",
       "      <td>composer</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm0530818</td>\n",
       "      <td>m.s. viswanathan</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>music_department,composer,actor</td>\n",
       "      <td>tt0154120,tt0432188,tt1441317,tt3400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60767</th>\n",
       "      <td>tt26998576</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.288</td>\n",
       "      <td>episode #1.288</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>comedy,drama,romance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm13810315</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>subho</td>\n",
       "      <td>nm13810315</td>\n",
       "      <td>rishav chakraborty</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt35747590,tt36958465,tt25910670,tt26908758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50074</th>\n",
       "      <td>tt12156036</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.251</td>\n",
       "      <td>episode #1.251</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>action</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0849850</td>\n",
       "      <td>director</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm0849850</td>\n",
       "      <td>imam tantowi</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>writer,director,art_director</td>\n",
       "      <td>tt3418604,tt0358793,tt1207735,tt0326595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst  titleType                   primaryTitle  \\\n",
       "75721  tt12528796  tvepisode                 episode #1.333   \n",
       "80184  tt10540368      short                      jellyfish   \n",
       "19864  tt21104030  tvepisode                  episode #2.15   \n",
       "76699   tt5907054  tvepisode                   episode #1.3   \n",
       "92991  tt14400866   tvseries            a couple of cuckoos   \n",
       "76434   tt0928280  tvepisode                      privilege   \n",
       "84004  tt22643502  tvepisode  episode dated 11 october 2022   \n",
       "80917   tt0352167      movie                amme bhagavathi   \n",
       "60767  tt26998576  tvepisode                 episode #1.288   \n",
       "50074  tt12156036  tvepisode                 episode #1.251   \n",
       "\n",
       "                       originalTitle  isAdult  startYear  endYear  \\\n",
       "75721                 episode #1.333        0       1938      0.0   \n",
       "80184                      jellyfish        0       2019      0.0   \n",
       "19864                  episode #2.15        0       2007      0.0   \n",
       "76699                   episode #1.3        0       1979      0.0   \n",
       "92991             kakkou no iinazuke        0       2022   2025.0   \n",
       "76434                      privilege        0       2007      0.0   \n",
       "84004  episode dated 11 october 2022        0       2022      0.0   \n",
       "80917                amme bhagavathi        0       1987      0.0   \n",
       "60767                 episode #1.288        0       2023      0.0   \n",
       "50074                 episode #1.251        0       2016      0.0   \n",
       "\n",
       "       runtimeMinutes                    genres  averageRating  ...  \\\n",
       "75721             0.0                     drama            0.0  ...   \n",
       "80184            13.0                     short            9.2  ...   \n",
       "19864             0.0         family,reality-tv            0.0  ...   \n",
       "76699             0.0                   unknown            0.0  ...   \n",
       "92991            23.0  animation,comedy,romance            6.8  ...   \n",
       "76434            44.0       crime,drama,mystery            8.1  ...   \n",
       "84004             0.0                      news            0.0  ...   \n",
       "80917             0.0                   unknown            6.1  ...   \n",
       "60767             0.0      comedy,drama,romance            0.0  ...   \n",
       "50074             0.0                    action            0.0  ...   \n",
       "\n",
       "           nconst  category         job                         characters  \\\n",
       "75721   nm5426054     actor     unknown                                      \n",
       "80184  nm10792182     actor     unknown                          caretaker   \n",
       "19864   nm1101797      self     unknown                  self - contestant   \n",
       "76699   nm0199858    writer  adaptation                                      \n",
       "92991   nm5928101     actor     unknown                  additional voices   \n",
       "76434   nm0454236     actor     unknown                       ernest foley   \n",
       "84004   nm4834517      self     unknown  self - fox business correspondent   \n",
       "80917   nm0530818  composer     unknown                                      \n",
       "60767  nm13810315     actor     unknown                              subho   \n",
       "50074   nm0849850  director     unknown                                      \n",
       "\n",
       "         nconst_1              primaryName birthYear  deathYear  \\\n",
       "75721   nm5426054              venu arvind       0.0        0.0   \n",
       "80184  nm10792182  trinidad asensio robles       0.0        0.0   \n",
       "19864   nm1101797             duncan james    1978.0        0.0   \n",
       "76699   nm0199858           carmen daniels       0.0     2006.0   \n",
       "92991   nm5928101            jacob eiseman       0.0        0.0   \n",
       "76434   nm0454236             richard kind    1956.0        0.0   \n",
       "84004   nm4834517         lauren simonetti       0.0        0.0   \n",
       "80917   nm0530818         m.s. viswanathan    1928.0     2015.0   \n",
       "60767  nm13810315       rishav chakraborty       0.0        0.0   \n",
       "50074   nm0849850             imam tantowi    1946.0        0.0   \n",
       "\n",
       "                      primaryProfession  \\\n",
       "75721             actor,director,writer   \n",
       "80184                             actor   \n",
       "19864  actor,soundtrack,archive_footage   \n",
       "76699                            writer   \n",
       "92991                             actor   \n",
       "76434           actor,writer,soundtrack   \n",
       "84004                   archive_footage   \n",
       "80917   music_department,composer,actor   \n",
       "60767                             actor   \n",
       "50074      writer,director,art_director   \n",
       "\n",
       "                                    knownForTitles  \n",
       "75721     tt13439272,tt0242256,tt0318993,tt2923826  \n",
       "80184                                   tt10540368  \n",
       "19864    tt0112004,tt1470249,tt12870980,tt12115616  \n",
       "76699      tt0211796,tt0229914,tt5378734,tt0214376  \n",
       "92991    tt3398540,tt10981954,tt9671916,tt13375866  \n",
       "76434      tt2096673,tt1024648,tt1019452,tt0120623  \n",
       "84004      tt9130562,tt3230032,tt7483086,tt3776548  \n",
       "80917      tt0154120,tt0432188,tt1441317,tt3400200  \n",
       "60767  tt35747590,tt36958465,tt25910670,tt26908758  \n",
       "50074      tt3418604,tt0358793,tt1207735,tt0326595  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Cleaned parquet saved as: /var/folders/zc/sdlj288n03ld3s3l_mzb9f0r0000gn/T/sample_imdb_cleaned.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "import tempfile\n",
    "import sys\n",
    "\n",
    "# === 1️⃣ Load your parquet ===\n",
    "FILE_URL = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-25_160707_UTC/imdb_sample_100k.parquet\"\n",
    "try:\n",
    "    df = pd.read_parquet(FILE_URL)\n",
    "    print(f\"Loaded dataframe: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load parquet file: {e}\")\n",
    "    print(\"Using a small dummy dataframe to demonstrate the pipeline.\")\n",
    "    data = {\n",
    "        'tconst': ['tt00001', 'tt00002', 'tt00003', 'tt00004'],\n",
    "        'primaryTitle': ['Movie 1', 'Movie 2', 'Movie 3', 'Bad Series'],\n",
    "        'genres': ['Action,Comedy', 'Drama', None, 'Drama'],\n",
    "        'attributes': ['attr1', 'attr2', 'attr3', 'attr4'],\n",
    "        'startYear': [2000, 2001, np.nan, 2010],\n",
    "        'endYear': [2000, 2001, np.nan, 2005], # Added bad data point\n",
    "        'runtimeMinutes': [120, np.nan, 90, 60],\n",
    "        'isAdult': [0, 't', np.nan, 0],\n",
    "        'characters': ['[\"Hero\"]', '[\"Villain\"]', np.nan, '[\"Anti-Hero\"]'],\n",
    "        'parentTconst': [np.nan, 'tt00001', np.nan, np.nan],\n",
    "        'titleId': [np.nan, 'tt00002_aka', np.nan, np.nan],\n",
    "        'ordering': [1, np.nan, 3, 1],\n",
    "        'title': [np.nan, 'Movie 2 Alt', np.nan, np.nan],\n",
    "        'isOriginalTitle': [np.nan, 0, np.nan, 1],\n",
    "        'tconst_1': ['tt00001', np.nan, 'tt00003', 'tt00004'],\n",
    "        'ordering_1': [1, np.nan, 3, 1],\n",
    "        'nconst': ['nm0001', np.nan, 'nm0003', 'nm0004'],\n",
    "        'nconst_1': ['nm0001', np.nan, 'nm0003', 'nm0004'],\n",
    "        'averageRating': [8.5, 7.2, 9.0, np.nan], # Added null rating\n",
    "        'numVotes': [1000, 500, 2000, np.nan],      # Added null votes\n",
    "        'job': [np.nan, 'actor', 'director', np.nan], # Added job\n",
    "        'deathYear': [np.nan, np.nan, 2020, np.nan] # Added deathYear\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# === 2️⃣ Define transformers ===\n",
    "\n",
    "class DropColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Drops specified columns.\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns, axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "class StringCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Strips whitespace, lowercases, and converts to string.\"\"\"\n",
    "    def __init__(self, columns): self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X2 = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X2.columns:\n",
    "                X2[col] = X2[col].astype(str).str.strip().str.lower().replace({'\\\\n':'', '\\\\t':''}, regex=True)\n",
    "        return X2\n",
    "\n",
    "\n",
    "class ListStringCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Cleans comma-separated list-strings (e.g., genres).\"\"\"\n",
    "    # --- UPDATED: Added fill_value parameter ---\n",
    "    def __init__(self, columns, separator=',', fill_value=''):\n",
    "        self.columns = columns\n",
    "        self.separator = separator\n",
    "        self.fill_value = fill_value\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X2 = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X2.columns:\n",
    "                # --- UPDATED: Use self.fill_value instead of hardcoded '' ---\n",
    "                X2[col] = X2[col].fillna(self.fill_value)\n",
    "                X2[col] = X2[col].apply(\n",
    "                    lambda s: self.separator.join(\n",
    "                        [item.strip().lower() for item in str(s).split(self.separator) if item.strip()]\n",
    "                    ) if s else self.fill_value if self.fill_value else '' # Handle case where fill_value is used\n",
    "                )\n",
    "        return X2\n",
    "\n",
    "\n",
    "class JSONStringParser(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Parses columns containing string representations of JSON lists.\"\"\"\n",
    "    def __init__(self, columns): self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def _parse(self, item):\n",
    "        if pd.isna(item): return ''\n",
    "        try:\n",
    "            # Try to load as JSON\n",
    "            parsed = json.loads(item)\n",
    "            if isinstance(parsed, list):\n",
    "                # Join list items into a comma-separated string\n",
    "                return ','.join(str(i).strip().lower() for i in parsed if i)\n",
    "        except Exception:\n",
    "            # If not JSON, just treat as a regular string\n",
    "            pass\n",
    "        return str(item).strip().lower()\n",
    "    def transform(self, X):\n",
    "        X2 = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X2.columns:\n",
    "                X2[col] = X2[col].apply(self._parse)\n",
    "        return X2\n",
    "\n",
    "\n",
    "class NumericNoopOrCoerce(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Ensure numeric columns are numeric (coerce bad -> NaN).\"\"\"\n",
    "    def __init__(self, columns): self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X2 = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X2.columns:\n",
    "                X2[col] = pd.to_numeric(X2[col], errors='coerce')\n",
    "        return X2\n",
    "\n",
    "\n",
    "class SpecialFillTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Handles specific rules for numeric fills and binary flags.\"\"\"\n",
    "    # --- UPDATED: Simplified __init__ ---\n",
    "    def __init__(self, start_year_col, isadult_col, zero_fill_cols):\n",
    "        self.start_year_col = start_year_col\n",
    "        self.zero_fill_cols = zero_fill_cols\n",
    "        self.isadult_col = isadult_col\n",
    "        self.start_median_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.start_year_col in X.columns:\n",
    "            # Ensure column is numeric before median\n",
    "            numeric_start = pd.to_numeric(X[self.start_year_col], errors='coerce')\n",
    "            self.start_median_ = numeric_start.median(skipna=True)\n",
    "            if pd.isna(self.start_median_):\n",
    "                self.start_median_ = 2000 # A reasonable fallback if all are null\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X2 = X.copy()\n",
    "        \n",
    "        # 1. Fill startYear: ffill + median fallback (as requested)\n",
    "        if self.start_year_col in X2.columns:\n",
    "            if self.start_median_ is None: # Should be set by fit, but as a safety\n",
    "                self.start_median_ = 2000\n",
    "            X2[self.start_year_col] = X2[self.start_year_col].ffill().fillna(self.start_median_).astype(int)\n",
    "        \n",
    "        # --- UPDATED: All special fills now use the zero_fill_cols list ---\n",
    "        \n",
    "        # 2. zero-fill all columns specified in the list (now includes endYear, ratings, etc.)\n",
    "        print(f\"Zero-filling columns: {self.zero_fill_cols}\")\n",
    "        for c in self.zero_fill_cols:\n",
    "            if c in X2.columns:\n",
    "                X2[c] = X2[c].fillna(0)\n",
    "        \n",
    "        # 3. normalize isAdult to 0/1\n",
    "        if self.isadult_col in X2.columns:\n",
    "            X2[self.isadult_col] = X2[self.isadult_col].fillna(0)\n",
    "            X2[self.isadult_col] = X2[self.isadult_col].apply(lambda x: 1 if str(x).strip().lower() in ['1','true','t'] else 0)\n",
    "        \n",
    "        # 4. Final check for endYear < startYear (good practice)\n",
    "        if 'startYear' in X2.columns and 'endYear' in X2.columns:\n",
    "            # Find rows where endYear is not 0 (not 'active') AND is less than startYear\n",
    "            mask = (X2['endYear'] != 0) & (X2['endYear'] < X2['startYear'])\n",
    "            if mask.any():\n",
    "                print(f\"Fixing {mask.sum()} rows where original endYear < startYear.\")\n",
    "                X2.loc[mask, 'endYear'] = X2.loc[mask, 'startYear']\n",
    "        \n",
    "        return X2\n",
    "\n",
    "\n",
    "class CustomOutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Removes rows based on Z-score of numeric columns.\"\"\"\n",
    "    def __init__(self, columns, threshold=4):\n",
    "        self.columns = columns\n",
    "        self.threshold = threshold\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X2 = X.copy()\n",
    "        valid = [c for c in self.columns if c in X2.columns and pd.api.types.is_numeric_dtype(X2[c])]\n",
    "        if not valid:\n",
    "            print(\"No numeric columns for outlier removal.\")\n",
    "            return X2\n",
    "        # Ensure data is float for zscore calculation\n",
    "        z = np.abs(stats.zscore(X2[valid].astype(float), nan_policy='omit'))\n",
    "        z = np.nan_to_num(z, nan=0) # Replace NaNs in z-scores with 0\n",
    "        mask = (z < self.threshold).all(axis=1)\n",
    "        print(f\"Outlier removal: retaining {mask.sum()} of {len(X2)} rows.\")\n",
    "        return X2[mask]\n",
    "\n",
    "# === 3️⃣ NEW TRANSFORMER: LeftoverNullFiller ===\n",
    "class LeftoverNullFiller(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Fills leftover nulls from joins or sparse data.\n",
    "    Fills specified string columns with 'unknown' (or other value).\n",
    "    Fills specified numeric columns with 0 (or other value).\n",
    "    \"\"\"\n",
    "    def __init__(self, string_cols, numeric_cols, string_fill='unknown', numeric_fill=0):\n",
    "        self.string_cols = string_cols\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.string_fill = string_fill\n",
    "        self.numeric_fill = numeric_fill\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X2 = X.copy()\n",
    "        print(f\"Running LeftoverNullFiller...\")\n",
    "        # Fill string columns\n",
    "        for col in self.string_cols:\n",
    "            if col in X2.columns:\n",
    "                # Fill NaNs and ensure type is string\n",
    "                X2[col] = X2[col].fillna(self.string_fill).astype(str)\n",
    "        \n",
    "        # Fill numeric columns\n",
    "        for col in self.numeric_cols:\n",
    "            if col in X2.columns:\n",
    "                # Fill NaNs and ensure type is int\n",
    "                X2[col] = X2[col].fillna(self.numeric_fill).astype(int)\n",
    "        \n",
    "        return X2\n",
    "\n",
    "# === 4️⃣ Define column groups and build pipeline ===\n",
    "\n",
    "DROP_COLS = ['attributes']\n",
    "CLEAN_STRING_COLS = [\n",
    "    'primaryTitle','originalTitle','title_akas','primaryName',\n",
    "    'titleType','region','language','types','category'\n",
    "]\n",
    "LIST_STRING_COLS = ['genres','directors','writers','primaryProfession','knownForTitles']\n",
    "JSON_STRING_COLS = ['characters']\n",
    "\n",
    "# All numeric cols, including the ones that were null\n",
    "NUMERIC_COLS = [\n",
    "    'startYear','endYear','runtimeMinutes','seasonNumber','episodeNumber',\n",
    "    'birthYear','deathYear','averageRating','numVotes',\n",
    "    'ordering', 'isOriginalTitle', 'ordering_1' # Add new numeric-like cols here\n",
    "]\n",
    "\n",
    "# Define columns for the new filler\n",
    "LEFTOVER_STRING_COLS = [\n",
    "    'parentTconst', 'titleId', 'title', \n",
    "    'tconst_1', 'nconst', 'nconst_1',\n",
    "    'job' # <-- ADDED 'job' HERE\n",
    "]\n",
    "LEFTOVER_NUMERIC_COLS = [\n",
    "    'ordering', 'isOriginalTitle', 'ordering_1'\n",
    "]\n",
    "\n",
    "\n",
    "cleaning_pipeline = Pipeline(steps=[\n",
    "    ('drop_cols', DropColumnTransformer(columns=DROP_COLS)),\n",
    "    ('clean_strings', StringCleaner(columns=CLEAN_STRING_COLS)),\n",
    "    # --- UPDATED: Pass fill_value='unknown' ---\n",
    "    ('clean_lists', ListStringCleaner(columns=LIST_STRING_COLS, fill_value='unknown')),\n",
    "    ('parse_json', JSONStringParser(columns=JSON_STRING_COLS)),\n",
    "    \n",
    "    # Coerce *all* potential numeric columns first\n",
    "    ('coerce_numeric', NumericNoopOrCoerce(columns=NUMERIC_COLS)),\n",
    "    \n",
    "    # --- UPDATED: special_fills now uses the new logic ---\n",
    "    ('special_fills', SpecialFillTransformer(\n",
    "        start_year_col='startYear',\n",
    "        isadult_col='isAdult',\n",
    "        zero_fill_cols=[\n",
    "            'runtimeMinutes', 'seasonNumber', 'episodeNumber', 'birthYear', # From your rules\n",
    "            'endYear',               # From your rules\n",
    "            'averageRating',         # To fix your complaint\n",
    "            'numVotes',              # To fix yourG complaint\n",
    "            'deathYear'              # <-- ADDED 'deathYear' HERE\n",
    "        ]\n",
    "    )),\n",
    "    \n",
    "    # This runs last to catch any remaining nulls in these specific columns\n",
    "    ('fill_leftovers', LeftoverNullFiller(\n",
    "        string_cols=LEFTOVER_STRING_COLS,\n",
    "        numeric_cols=LEFTOVER_NUMERIC_COLS,\n",
    "        string_fill='unknown',\n",
    "        numeric_fill=0\n",
    "    )),\n",
    "\n",
    "    # Optional outlier removal (uncomment to use)\n",
    "    # ('remove_outliers', CustomOutlierRemover(columns=['runtimeMinutes','numVotes','averageRating'], threshold=4))\n",
    "])\n",
    "\n",
    "# === 5️⃣ Apply cleaning ===\n",
    "df_cleaned = cleaning_pipeline.fit_transform(df)\n",
    "print(f\"✅ Cleaning done: {df_cleaned.shape[0]} rows, {df_cleaned.shape[1]} columns\")\n",
    "\n",
    "# === 6️⃣ Check results ===\n",
    "print(\"\\n--- Null count per column ---\")\n",
    "nulls = df_cleaned.isna().sum()\n",
    "if nulls.sum() == 0:\n",
    "    print(\"🎉 All null values have been handled! 🎉\")\n",
    "else:\n",
    "    print(nulls[nulls > 0])\n",
    "\n",
    "print(\"\\n--- Sample rows (post-cleaning) ---\")\n",
    "# Use display() if in a notebook, otherwise print()\n",
    "if 'ipykernel' in sys.modules:\n",
    "    display(df_cleaned.sample(min(10, len(df_cleaned)), random_state=42))\n",
    "else:\n",
    "    print(df_cleaned.sample(min(10, len(df_cleaned)), random_state=42))\n",
    "\n",
    "# === 7️⃣ Save cleaned data ===\n",
    "try:\n",
    "    OUTPUT_FILE = tempfile.gettempdir() + \"/sample_imdb_cleaned.parquet\"\n",
    "    df_cleaned.to_parquet(OUTPUT_FILE, index=False, engine='pyarrow')\n",
    "    print(f\"\\n💾 Cleaned parquet saved as: {OUTPUT_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nFailed to save parquet file: {e}\")\n",
    "    print(\"This can happen if 'pyarrow' is not installed. Try: pip install pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e70b411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_CSV = tempfile.gettempdir() + \"/sample_imdb_cleaned.csv\"\n",
    "df_cleaned.to_csv(OUTPUT_FILE_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfb2b58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>...</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "      <th>nconst_1</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82847</th>\n",
       "      <td>tt9463208</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 24 november 2018</td>\n",
       "      <td>episode dated 24 november 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk-show</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1930056</td>\n",
       "      <td>writer</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm1930056</td>\n",
       "      <td>francisco quintanar</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>director,writer,miscellaneous</td>\n",
       "      <td>tt0943381,tt0373497,tt1560991,tt0375383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71587</th>\n",
       "      <td>tt26907800</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.24</td>\n",
       "      <td>episode #1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0342533</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm0342533</td>\n",
       "      <td>amparo grisales</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actress,producer</td>\n",
       "      <td>tt0450340,tt6809396,tt1585368,tt0257282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69171</th>\n",
       "      <td>tt0282552</td>\n",
       "      <td>movie</td>\n",
       "      <td>steal</td>\n",
       "      <td>riders</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>action,crime,thriller</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0565327</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>frank</td>\n",
       "      <td>nm0565327</td>\n",
       "      <td>steven mccarthy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor,writer,producer</td>\n",
       "      <td>tt3230854,tt4571340,tt11525188,tt6236572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69439</th>\n",
       "      <td>tt16440734</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.257</td>\n",
       "      <td>episode #1.257</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm3333342</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>melusi dlamini</td>\n",
       "      <td>nm3333342</td>\n",
       "      <td>zolisa xaluva</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt7416536,tt21448346,tt13453828,tt12599346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62654</th>\n",
       "      <td>tt14737288</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.121</td>\n",
       "      <td>episode #1.121</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama,family,romance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm12559942</td>\n",
       "      <td>editor</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm12559942</td>\n",
       "      <td>pandidurai</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>editor</td>\n",
       "      <td>tt13570010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37769</th>\n",
       "      <td>tt33455973</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.408</td>\n",
       "      <td>episode #1.408</td>\n",
       "      <td>0</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>news</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm16528122</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>self - reporter</td>\n",
       "      <td>nm16528122</td>\n",
       "      <td>ed goetze</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>tt33384753,tt33447764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76330</th>\n",
       "      <td>tt6140782</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 18 october 2016</td>\n",
       "      <td>episode dated 18 october 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>news</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm2166842</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>self - fox news chief legal correspondent</td>\n",
       "      <td>nm2166842</td>\n",
       "      <td>shannon bream</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>writer,producer,actress</td>\n",
       "      <td>tt4649466,tt14624264,tt7406432,tt0770614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67627</th>\n",
       "      <td>tt4831952</td>\n",
       "      <td>short</td>\n",
       "      <td>a motel story</td>\n",
       "      <td>a motel story</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>crime,drama,short</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1428476</td>\n",
       "      <td>director</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm1428476</td>\n",
       "      <td>nick epstein</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>visual_effects,director,writer</td>\n",
       "      <td>tt0437086,tt1630029,tt0206634,tt8355738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89842</th>\n",
       "      <td>tt14860046</td>\n",
       "      <td>tvseries</td>\n",
       "      <td>casa zurli</td>\n",
       "      <td>casa zurli</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>family</td>\n",
       "      <td>5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>nm2658421</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>self - guest</td>\n",
       "      <td>nm2658421</td>\n",
       "      <td>marius urzica</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt0464955,tt14860046,tt1027229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41257</th>\n",
       "      <td>tt8028800</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.75</td>\n",
       "      <td>episode #1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0260778</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>vítor duque</td>\n",
       "      <td>nm0260778</td>\n",
       "      <td>luís esparteiro</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor,miscellaneous,archive_footage</td>\n",
       "      <td>tt6183736,tt8960296,tt0135113,tt1980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52295</th>\n",
       "      <td>tt30420563</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.1640</td>\n",
       "      <td>episode #1.1640</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm9494664</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>rajveer luthra</td>\n",
       "      <td>nm9494664</td>\n",
       "      <td>paras kalnawat</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor,producer</td>\n",
       "      <td>tt11867666,tt7147670,tt8160822,tt7762954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58712</th>\n",
       "      <td>tt7401588</td>\n",
       "      <td>movie</td>\n",
       "      <td>instant family</td>\n",
       "      <td>instant family</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>comedy,drama</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0506100</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td></td>\n",
       "      <td>nm0506100</td>\n",
       "      <td>stephen levinson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>producer,writer,manager</td>\n",
       "      <td>tt0387199,tt7401588,tt1524137,tt2891574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67638</th>\n",
       "      <td>tt13002282</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 30 december 2015</td>\n",
       "      <td>episode dated 30 december 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>news,talk-show</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm2866058</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>self - host</td>\n",
       "      <td>nm2866058</td>\n",
       "      <td>anna planken</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>tt0486535,tt35993282,tt0834026,tt0781288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68550</th>\n",
       "      <td>tt38278954</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #12.23</td>\n",
       "      <td>episode #12.23</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>comedy,drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm8258968</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td>manuela</td>\n",
       "      <td>nm8258968</td>\n",
       "      <td>rosie pellizzer</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actress</td>\n",
       "      <td>tt1831897,tt10440654,tt14520400,tt1192302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83937</th>\n",
       "      <td>tt5656016</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.1</td>\n",
       "      <td>episode #1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>romance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0945677</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>junkichi hongo</td>\n",
       "      <td>nm0945677</td>\n",
       "      <td>takaya yamauchi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt8649224,tt15127988,tt0088093,tt27930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64119</th>\n",
       "      <td>tt10403552</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 21 march 2016</td>\n",
       "      <td>episode dated 21 march 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>talk-show</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1041026</td>\n",
       "      <td>writer</td>\n",
       "      <td>created by</td>\n",
       "      <td></td>\n",
       "      <td>nm1041026</td>\n",
       "      <td>dianne nelmes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>writer,producer,miscellaneous</td>\n",
       "      <td>tt0181261,tt0217211,tt0101068,tt0133021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74735</th>\n",
       "      <td>tt0522991</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>violated</td>\n",
       "      <td>violated</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>drama,romance</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0202781</td>\n",
       "      <td>composer</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm0202781</td>\n",
       "      <td>martin davich</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>music_department,composer,producer</td>\n",
       "      <td>tt0108757,tt0197182,tt0058796,tt0098749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14240</th>\n",
       "      <td>tt21144008</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.417</td>\n",
       "      <td>episode #1.417</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm10283735</td>\n",
       "      <td>writer</td>\n",
       "      <td>screenplay</td>\n",
       "      <td></td>\n",
       "      <td>nm10283735</td>\n",
       "      <td>rohini ninawe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>writer,music_department</td>\n",
       "      <td>tt15426128,tt10305452,tt13654230,tt15742642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25902</th>\n",
       "      <td>tt8960466</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #3.18</td>\n",
       "      <td>episode #3.18</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>comedy,romance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm2750167</td>\n",
       "      <td>editor</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm2750167</td>\n",
       "      <td>hristos markakis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>editor,producer,editorial_department</td>\n",
       "      <td>tt11297308,tt7467054,tt10983532,tt20784430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61789</th>\n",
       "      <td>tt6200314</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>lars hat lona als moderatorin für city-radio g...</td>\n",
       "      <td>lars hat lona als moderatorin für city-radio g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>drama,romance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0270522</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>alexander albrecht</td>\n",
       "      <td>nm0270522</td>\n",
       "      <td>sebastian feicht</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor,archive_footage</td>\n",
       "      <td>tt0108977,tt27141512,tt0118503,tt0806910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13830</th>\n",
       "      <td>tt0864921</td>\n",
       "      <td>movie</td>\n",
       "      <td>a castle in spain</td>\n",
       "      <td>un château en espagne</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>comedy,drama</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0110507</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td>emma breal</td>\n",
       "      <td>nm0110507</td>\n",
       "      <td>anne brochet</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actress,director,writer</td>\n",
       "      <td>tt0099334,tt0093505,tt0109682,tt0103110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19345</th>\n",
       "      <td>tt15458710</td>\n",
       "      <td>movie</td>\n",
       "      <td>ethiroli</td>\n",
       "      <td>ethiroli</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>crime,drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm10082549</td>\n",
       "      <td>writer</td>\n",
       "      <td>based on the story by</td>\n",
       "      <td></td>\n",
       "      <td>nm10082549</td>\n",
       "      <td>m. srinivasan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>writer,producer,director</td>\n",
       "      <td>tt37797044,tt37813044,tt12368132,tt37797043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76720</th>\n",
       "      <td>tt28772847</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #8.78</td>\n",
       "      <td>episode #8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm5626503</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm5626503</td>\n",
       "      <td>africa tsoai</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt2094533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48997</th>\n",
       "      <td>tt31041591</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 19 october 2022</td>\n",
       "      <td>episode dated 19 october 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>documentary,talk-show</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm11614318</td>\n",
       "      <td>writer</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm11614318</td>\n",
       "      <td>bruno amstutz</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>writer,camera_department,director</td>\n",
       "      <td>tt1025537,tt12400494,tt23626090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24581</th>\n",
       "      <td>tt26903316</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 2 september 2022</td>\n",
       "      <td>episode dated 2 september 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>news</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm4655938</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>self - host</td>\n",
       "      <td>nm4655938</td>\n",
       "      <td>germán paoloski</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor,producer,archive_footage</td>\n",
       "      <td>tt0373516,tt1570374,tt0473575,tt26336930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45219</th>\n",
       "      <td>tt1097743</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.2675</td>\n",
       "      <td>episode #1.2675</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>drama,romance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0291785</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ambrosia moore</td>\n",
       "      <td>nm0291785</td>\n",
       "      <td>adrienne frantz</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actress,sound_department,soundtrack</td>\n",
       "      <td>tt0092325,tt0069658,tt1489428,tt4175148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30659</th>\n",
       "      <td>tt8195610</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.8</td>\n",
       "      <td>episode #1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0739589</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td>mercedes (1988)</td>\n",
       "      <td>nm0739589</td>\n",
       "      <td>tina romero</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actress,producer</td>\n",
       "      <td>tt0075666,tt0215397,tt0084335,tt0134695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63807</th>\n",
       "      <td>tt27051638</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.1322</td>\n",
       "      <td>episode #1.1322</td>\n",
       "      <td>0</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk-show</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm3634990</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>self - host</td>\n",
       "      <td>nm3634990</td>\n",
       "      <td>amaury jr.</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>writer,actor,archive_footage</td>\n",
       "      <td>tt1235548,tt35319835,tt1997594,tt7162732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80766</th>\n",
       "      <td>tt26426921</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.104</td>\n",
       "      <td>episode #1.104</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0571651</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td></td>\n",
       "      <td>nm0571651</td>\n",
       "      <td>colin mckeown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>producer,miscellaneous,writer</td>\n",
       "      <td>tt1340758,tt2937752,tt8531560,tt2390624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37058</th>\n",
       "      <td>tt32398327</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.277</td>\n",
       "      <td>episode #1.277</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm15997254</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm15997254</td>\n",
       "      <td>anurag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt31986863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst  titleType  \\\n",
       "82847   tt9463208  tvepisode   \n",
       "71587  tt26907800  tvepisode   \n",
       "69171   tt0282552      movie   \n",
       "69439  tt16440734  tvepisode   \n",
       "62654  tt14737288  tvepisode   \n",
       "37769  tt33455973  tvepisode   \n",
       "76330   tt6140782  tvepisode   \n",
       "67627   tt4831952      short   \n",
       "89842  tt14860046   tvseries   \n",
       "41257   tt8028800  tvepisode   \n",
       "52295  tt30420563  tvepisode   \n",
       "58712   tt7401588      movie   \n",
       "67638  tt13002282  tvepisode   \n",
       "68550  tt38278954  tvepisode   \n",
       "83937   tt5656016  tvepisode   \n",
       "64119  tt10403552  tvepisode   \n",
       "74735   tt0522991  tvepisode   \n",
       "14240  tt21144008  tvepisode   \n",
       "25902   tt8960466  tvepisode   \n",
       "61789   tt6200314  tvepisode   \n",
       "13830   tt0864921      movie   \n",
       "19345  tt15458710      movie   \n",
       "76720  tt28772847  tvepisode   \n",
       "48997  tt31041591  tvepisode   \n",
       "24581  tt26903316  tvepisode   \n",
       "45219   tt1097743  tvepisode   \n",
       "30659   tt8195610  tvepisode   \n",
       "63807  tt27051638  tvepisode   \n",
       "80766  tt26426921  tvepisode   \n",
       "37058  tt32398327  tvepisode   \n",
       "\n",
       "                                            primaryTitle  \\\n",
       "82847                     episode dated 24 november 2018   \n",
       "71587                                      episode #1.24   \n",
       "69171                                              steal   \n",
       "69439                                     episode #1.257   \n",
       "62654                                     episode #1.121   \n",
       "37769                                     episode #1.408   \n",
       "76330                      episode dated 18 october 2016   \n",
       "67627                                      a motel story   \n",
       "89842                                         casa zurli   \n",
       "41257                                      episode #1.75   \n",
       "52295                                    episode #1.1640   \n",
       "58712                                     instant family   \n",
       "67638                     episode dated 30 december 2015   \n",
       "68550                                     episode #12.23   \n",
       "83937                                       episode #1.1   \n",
       "64119                        episode dated 21 march 2016   \n",
       "74735                                           violated   \n",
       "14240                                     episode #1.417   \n",
       "25902                                      episode #3.18   \n",
       "61789  lars hat lona als moderatorin für city-radio g...   \n",
       "13830                                  a castle in spain   \n",
       "19345                                           ethiroli   \n",
       "76720                                      episode #8.78   \n",
       "48997                      episode dated 19 october 2022   \n",
       "24581                     episode dated 2 september 2022   \n",
       "45219                                    episode #1.2675   \n",
       "30659                                       episode #1.8   \n",
       "63807                                    episode #1.1322   \n",
       "80766                                     episode #1.104   \n",
       "37058                                     episode #1.277   \n",
       "\n",
       "                                           originalTitle  isAdult  startYear  \\\n",
       "82847                     episode dated 24 november 2018        0       2018   \n",
       "71587                                      episode #1.24        0       1976   \n",
       "69171                                             riders        0       2002   \n",
       "69439                                     episode #1.257        0       2022   \n",
       "62654                                     episode #1.121        0       1979   \n",
       "37769                                     episode #1.408        0       1970   \n",
       "76330                      episode dated 18 october 2016        0       2016   \n",
       "67627                                      a motel story        0       2017   \n",
       "89842                                         casa zurli        0       2020   \n",
       "41257                                      episode #1.75        0       2018   \n",
       "52295                                    episode #1.1640        0       2023   \n",
       "58712                                     instant family        0       2018   \n",
       "67638                     episode dated 30 december 2015        0       2015   \n",
       "68550                                     episode #12.23        0       2022   \n",
       "83937                                       episode #1.1        0       2016   \n",
       "64119                        episode dated 21 march 2016        0       2016   \n",
       "74735                                           violated        0       1995   \n",
       "14240                                     episode #1.417        0       2022   \n",
       "25902                                      episode #3.18        0       2017   \n",
       "61789  lars hat lona als moderatorin für city-radio g...        0       1996   \n",
       "13830                              un château en espagne        0       2007   \n",
       "19345                                           ethiroli        0       2000   \n",
       "76720                                      episode #8.78        0       2024   \n",
       "48997                      episode dated 19 october 2022        0       2022   \n",
       "24581                     episode dated 2 september 2022        0       2022   \n",
       "45219                                    episode #1.2675        0       1997   \n",
       "30659                                       episode #1.8        0       1987   \n",
       "63807                                    episode #1.1322        0       1989   \n",
       "80766                                     episode #1.104        0       2019   \n",
       "37058                                     episode #1.277        0       2024   \n",
       "\n",
       "       endYear  runtimeMinutes                 genres  averageRating  ...  \\\n",
       "82847      0.0             0.0              talk-show            0.0  ...   \n",
       "71587      0.0             0.0                  drama            0.0  ...   \n",
       "69171      0.0            83.0  action,crime,thriller            5.4  ...   \n",
       "69439      0.0             0.0                  drama            0.0  ...   \n",
       "62654      0.0             0.0   drama,family,romance            0.0  ...   \n",
       "37769      0.0            30.0                   news            0.0  ...   \n",
       "76330      0.0             0.0                   news            0.0  ...   \n",
       "67627      0.0            13.0      crime,drama,short            0.0  ...   \n",
       "89842      0.0            45.0                 family            5.1  ...   \n",
       "41257      0.0             0.0                  drama            0.0  ...   \n",
       "52295      0.0             0.0                  drama            0.0  ...   \n",
       "58712      0.0           118.0           comedy,drama            7.3  ...   \n",
       "67638      0.0           210.0         news,talk-show            0.0  ...   \n",
       "68550      0.0             0.0           comedy,drama            0.0  ...   \n",
       "83937      0.0            54.0                romance            0.0  ...   \n",
       "64119      0.0           120.0              talk-show            0.0  ...   \n",
       "74735      0.0            45.0          drama,romance            7.3  ...   \n",
       "14240      0.0             0.0                  drama            0.0  ...   \n",
       "25902      0.0             0.0         comedy,romance            0.0  ...   \n",
       "61789      0.0            24.0          drama,romance            0.0  ...   \n",
       "13830      0.0            92.0           comedy,drama            6.2  ...   \n",
       "19345      0.0             0.0            crime,drama            0.0  ...   \n",
       "76720      0.0            30.0                  drama            0.0  ...   \n",
       "48997      0.0             0.0  documentary,talk-show            0.0  ...   \n",
       "24581      0.0             0.0                   news            0.0  ...   \n",
       "45219      0.0            25.0          drama,romance            0.0  ...   \n",
       "30659      0.0            22.0                unknown            0.0  ...   \n",
       "63807      0.0             0.0              talk-show            0.0  ...   \n",
       "80766      0.0             0.0                  drama            0.0  ...   \n",
       "37058      0.0             0.0                  drama            0.0  ...   \n",
       "\n",
       "           nconst  category                    job  \\\n",
       "82847   nm1930056    writer                unknown   \n",
       "71587   nm0342533   actress                unknown   \n",
       "69171   nm0565327     actor                unknown   \n",
       "69439   nm3333342     actor                unknown   \n",
       "62654  nm12559942    editor                unknown   \n",
       "37769  nm16528122      self                unknown   \n",
       "76330   nm2166842      self                unknown   \n",
       "67627   nm1428476  director                unknown   \n",
       "89842   nm2658421      self                unknown   \n",
       "41257   nm0260778     actor                unknown   \n",
       "52295   nm9494664     actor                unknown   \n",
       "58712   nm0506100  producer               producer   \n",
       "67638   nm2866058      self                unknown   \n",
       "68550   nm8258968   actress                unknown   \n",
       "83937   nm0945677     actor                unknown   \n",
       "64119   nm1041026    writer             created by   \n",
       "74735   nm0202781  composer                unknown   \n",
       "14240  nm10283735    writer             screenplay   \n",
       "25902   nm2750167    editor                unknown   \n",
       "61789   nm0270522     actor                unknown   \n",
       "13830   nm0110507   actress                unknown   \n",
       "19345  nm10082549    writer  based on the story by   \n",
       "76720   nm5626503     actor                unknown   \n",
       "48997  nm11614318    writer                unknown   \n",
       "24581   nm4655938      self                unknown   \n",
       "45219   nm0291785   actress                unknown   \n",
       "30659   nm0739589   actress                unknown   \n",
       "63807   nm3634990      self                unknown   \n",
       "80766   nm0571651  producer               producer   \n",
       "37058  nm15997254     actor                unknown   \n",
       "\n",
       "                                      characters    nconst_1  \\\n",
       "82847                                              nm1930056   \n",
       "71587                                              nm0342533   \n",
       "69171                                      frank   nm0565327   \n",
       "69439                             melusi dlamini   nm3333342   \n",
       "62654                                             nm12559942   \n",
       "37769                            self - reporter  nm16528122   \n",
       "76330  self - fox news chief legal correspondent   nm2166842   \n",
       "67627                                              nm1428476   \n",
       "89842                               self - guest   nm2658421   \n",
       "41257                                vítor duque   nm0260778   \n",
       "52295                             rajveer luthra   nm9494664   \n",
       "58712                                              nm0506100   \n",
       "67638                                self - host   nm2866058   \n",
       "68550                                    manuela   nm8258968   \n",
       "83937                             junkichi hongo   nm0945677   \n",
       "64119                                              nm1041026   \n",
       "74735                                              nm0202781   \n",
       "14240                                             nm10283735   \n",
       "25902                                              nm2750167   \n",
       "61789                         alexander albrecht   nm0270522   \n",
       "13830                                 emma breal   nm0110507   \n",
       "19345                                             nm10082549   \n",
       "76720                                              nm5626503   \n",
       "48997                                             nm11614318   \n",
       "24581                                self - host   nm4655938   \n",
       "45219                             ambrosia moore   nm0291785   \n",
       "30659                            mercedes (1988)   nm0739589   \n",
       "63807                                self - host   nm3634990   \n",
       "80766                                              nm0571651   \n",
       "37058                                             nm15997254   \n",
       "\n",
       "               primaryName birthYear  deathYear  \\\n",
       "82847  francisco quintanar    1958.0        0.0   \n",
       "71587      amparo grisales    1956.0        0.0   \n",
       "69171      steven mccarthy       0.0        0.0   \n",
       "69439        zolisa xaluva    1981.0        0.0   \n",
       "62654           pandidurai       0.0        0.0   \n",
       "37769            ed goetze       0.0        0.0   \n",
       "76330        shannon bream    1970.0        0.0   \n",
       "67627         nick epstein       0.0        0.0   \n",
       "89842        marius urzica       0.0        0.0   \n",
       "41257      luís esparteiro    1959.0        0.0   \n",
       "52295       paras kalnawat    1996.0        0.0   \n",
       "58712     stephen levinson       0.0        0.0   \n",
       "67638         anna planken    1980.0        0.0   \n",
       "68550      rosie pellizzer    1993.0        0.0   \n",
       "83937      takaya yamauchi       0.0        0.0   \n",
       "64119        dianne nelmes       0.0        0.0   \n",
       "74735        martin davich       0.0        0.0   \n",
       "14240        rohini ninawe       0.0        0.0   \n",
       "25902     hristos markakis       0.0        0.0   \n",
       "61789     sebastian feicht    1973.0        0.0   \n",
       "13830         anne brochet    1966.0        0.0   \n",
       "19345        m. srinivasan       0.0        0.0   \n",
       "76720         africa tsoai       0.0        0.0   \n",
       "48997        bruno amstutz    1973.0        0.0   \n",
       "24581      germán paoloski       0.0        0.0   \n",
       "45219      adrienne frantz    1978.0        0.0   \n",
       "30659          tina romero    1949.0        0.0   \n",
       "63807           amaury jr.    1950.0        0.0   \n",
       "80766        colin mckeown       0.0        0.0   \n",
       "37058               anurag       0.0        0.0   \n",
       "\n",
       "                          primaryProfession  \\\n",
       "82847         director,writer,miscellaneous   \n",
       "71587                      actress,producer   \n",
       "69171                 actor,writer,producer   \n",
       "69439                                 actor   \n",
       "62654                                editor   \n",
       "37769                               unknown   \n",
       "76330               writer,producer,actress   \n",
       "67627        visual_effects,director,writer   \n",
       "89842                                 actor   \n",
       "41257   actor,miscellaneous,archive_footage   \n",
       "52295                        actor,producer   \n",
       "58712               producer,writer,manager   \n",
       "67638                         miscellaneous   \n",
       "68550                               actress   \n",
       "83937                                 actor   \n",
       "64119         writer,producer,miscellaneous   \n",
       "74735    music_department,composer,producer   \n",
       "14240               writer,music_department   \n",
       "25902  editor,producer,editorial_department   \n",
       "61789                 actor,archive_footage   \n",
       "13830               actress,director,writer   \n",
       "19345              writer,producer,director   \n",
       "76720                                 actor   \n",
       "48997     writer,camera_department,director   \n",
       "24581        actor,producer,archive_footage   \n",
       "45219   actress,sound_department,soundtrack   \n",
       "30659                      actress,producer   \n",
       "63807          writer,actor,archive_footage   \n",
       "80766         producer,miscellaneous,writer   \n",
       "37058                                 actor   \n",
       "\n",
       "                                    knownForTitles  \n",
       "82847      tt0943381,tt0373497,tt1560991,tt0375383  \n",
       "71587      tt0450340,tt6809396,tt1585368,tt0257282  \n",
       "69171     tt3230854,tt4571340,tt11525188,tt6236572  \n",
       "69439   tt7416536,tt21448346,tt13453828,tt12599346  \n",
       "62654                                   tt13570010  \n",
       "37769                        tt33384753,tt33447764  \n",
       "76330     tt4649466,tt14624264,tt7406432,tt0770614  \n",
       "67627      tt0437086,tt1630029,tt0206634,tt8355738  \n",
       "89842               tt0464955,tt14860046,tt1027229  \n",
       "41257      tt6183736,tt8960296,tt0135113,tt1980858  \n",
       "52295     tt11867666,tt7147670,tt8160822,tt7762954  \n",
       "58712      tt0387199,tt7401588,tt1524137,tt2891574  \n",
       "67638     tt0486535,tt35993282,tt0834026,tt0781288  \n",
       "68550    tt1831897,tt10440654,tt14520400,tt1192302  \n",
       "83937    tt8649224,tt15127988,tt0088093,tt27930733  \n",
       "64119      tt0181261,tt0217211,tt0101068,tt0133021  \n",
       "74735      tt0108757,tt0197182,tt0058796,tt0098749  \n",
       "14240  tt15426128,tt10305452,tt13654230,tt15742642  \n",
       "25902   tt11297308,tt7467054,tt10983532,tt20784430  \n",
       "61789     tt0108977,tt27141512,tt0118503,tt0806910  \n",
       "13830      tt0099334,tt0093505,tt0109682,tt0103110  \n",
       "19345  tt37797044,tt37813044,tt12368132,tt37797043  \n",
       "76720                                    tt2094533  \n",
       "48997              tt1025537,tt12400494,tt23626090  \n",
       "24581     tt0373516,tt1570374,tt0473575,tt26336930  \n",
       "45219      tt0092325,tt0069658,tt1489428,tt4175148  \n",
       "30659      tt0075666,tt0215397,tt0084335,tt0134695  \n",
       "63807     tt1235548,tt35319835,tt1997594,tt7162732  \n",
       "80766      tt1340758,tt2937752,tt8531560,tt2390624  \n",
       "37058                                   tt31986863  \n",
       "\n",
       "[30 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7️⃣ Save cleaned data ===\n",
    "try:\n",
    "    OUTPUT_FILE = tempfile.gettempdir() + \"/3sample_imdb_cleaned.parquet\"\n",
    "    df_cleaned.to_parquet(OUTPUT_FILE, index=False, engine='pyarrow')\n",
    "    print(f\"\\n💾 Cleaned parquet saved as: {OUTPUT_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nFailed to save parquet file: {e}\")\n",
    "    print(\"This can happen if 'pyarrow' is not installed. Try: pip install pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e8ac7",
   "metadata": {},
   "source": [
    "# Code in duckdb based on the instruction above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c033b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "import tempfile\n",
    "import sys\n",
    "\n",
    "# === 1️⃣ Define file paths ===\n",
    "FILE_URL = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-25_165557_UTC/imdb_cleaned_for_colleagues.parquet\"\n",
    "OUTPUT_FILE_CSV = tempfile.gettempdir() + \"/sample_imdb_cleaned_duckdb.csv\"\n",
    "\n",
    "# === 2️⃣ Define column groups (for SQL) ===\n",
    "# These match your Python lists\n",
    "CLEAN_STRING_COLS = [\n",
    "    'primaryTitle','originalTitle','title_akas','primaryName',\n",
    "    'titleType','region','language','types','category'\n",
    "]\n",
    "LIST_STRING_COLS = ['genres','directors','writers','primaryProfession','knownForTitles']\n",
    "JSON_STRING_COLS = ['characters']\n",
    "ZERO_FILL_COLS = [\n",
    "    'runtimeMinutes', 'seasonNumber', 'episodeNumber', 'birthYear',\n",
    "    'endYear', 'averageRating', 'numVotes', 'deathYear'\n",
    "]\n",
    "LEFTOVER_STRING_COLS = [\n",
    "    'parentTconst', 'titleId', 'title', \n",
    "    'tconst_1', 'nconst', 'nconst_1', 'job'\n",
    "]\n",
    "LEFTOVER_NUMERIC_COLS = [\n",
    "    'ordering', 'isOriginalTitle', 'ordering_1'\n",
    "]\n",
    "\n",
    "# === 3️⃣ Build the cleaning query ===\n",
    "# We build the query dynamically to make it easier to maintain\n",
    "def build_cleaning_query(file_url, output_csv):\n",
    "    \n",
    "    # --- Helper transformations ---\n",
    "    \n",
    "    # `lower(trim(col))`\n",
    "    def sql_clean_string(col):\n",
    "        return f\"lower(trim({col}::VARCHAR)) AS {col}\"\n",
    "\n",
    "    # `list_aggr(list_transform(string_split(COALESCE(col, 'unknown'), ','), ...), ',')`\n",
    "    def sql_clean_list(col):\n",
    "        return f\"list_aggr(list_transform(string_split(COALESCE({col}::VARCHAR, 'unknown'), ','), item -> lower(trim(item))), ',') AS {col}\"\n",
    "\n",
    "    # `COALESCE(try_cast(...), 0)`\n",
    "    def sql_zero_fill(col):\n",
    "        # averageRating is float, others are int\n",
    "        cast_type = \"DOUBLE\" if col == 'averageRating' else \"INTEGER\"\n",
    "        return f\"COALESCE(try_cast({col} AS {cast_type}), 0) AS {col}\"\n",
    "\n",
    "    # `COALESCE(col, 'unknown')`\n",
    "    def sql_leftover_string(col):\n",
    "        return f\"COALESCE({col}::VARCHAR, 'unknown') AS {col}\"\n",
    "\n",
    "    # `COALESCE(try_cast(...), 0)`\n",
    "    def sql_leftover_numeric(col):\n",
    "        return f\"COALESCE(try_cast({col} AS INTEGER), 0) AS {col}\"\n",
    "\n",
    "    # --- Start building the main query ---\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    -- Load httpfs to read remote parquet\n",
    "    INSTALL httpfs;\n",
    "    LOAD httpfs;\n",
    "\n",
    "    -- Create a temporary table with a row_id to replicate pandas.ffill()\n",
    "    CREATE TEMPORARY TABLE base_data AS\n",
    "    SELECT \n",
    "        row_number() OVER () AS _row_id, \n",
    "        * FROM read_parquet('{file_url}');\n",
    "\n",
    "    -- Calculate median startYear (for ffill fallback)\n",
    "    CREATE TEMPORARY TABLE settings AS\n",
    "    SELECT \n",
    "        median(try_cast(startYear AS INTEGER)) AS median_start_year \n",
    "    FROM base_data;\n",
    "\n",
    "    -- Define the full cleaning pipeline as a series of CTEs\n",
    "    WITH \n",
    "    \n",
    "    -- Step 2 & 5: Coerce types, clean strings\n",
    "    type_coerce AS (\n",
    "        SELECT\n",
    "            _row_id,\n",
    "            tconst,\n",
    "\n",
    "            -- String Cleaning\n",
    "            {', '.join([sql_clean_string(c) for c in CLEAN_STRING_COLS])},\n",
    "\n",
    "            -- Raw List/JSON columns (to be cleaned next)\n",
    "            {', '.join(LIST_STRING_COLS)},\n",
    "            {', '.join(JSON_STRING_COLS)},\n",
    "\n",
    "            -- Raw Numeric columns (to be filled next)\n",
    "            try_cast(startYear AS INTEGER) AS startYear,\n",
    "            {', '.join(ZERO_FILL_COLS)}, -- Select raw columns\n",
    "            \n",
    "            -- isAdult (special case)\n",
    "            isAdult AS isAdult_raw,\n",
    "\n",
    "            -- Raw Leftover columns\n",
    "            {', '.join(LEFTOVER_STRING_COLS)},\n",
    "            {', '.join(LEFTOVER_NUMERIC_COLS)}\n",
    "            \n",
    "        FROM base_data\n",
    "        -- 'attributes' column is dropped by not being selected\n",
    "    ),\n",
    "\n",
    "    -- Step 3 & 4: Clean Lists and JSON\n",
    "    clean_lists_json AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            -- List cleaning logic\n",
    "            {', '.join([sql_clean_list(c) for c in LIST_STRING_COLS])},\n",
    "\n",
    "            -- JSON parsing logic for 'characters'\n",
    "            COALESCE(\n",
    "                list_aggr(list_transform(json_extract(try_cast(characters AS JSON), '$[*]'), e -> lower(trim(e::VARCHAR))), ','),\n",
    "                lower(trim(COALESCE(characters, '')))\n",
    "            ) AS characters\n",
    "\n",
    "        -- Exclude raw columns\n",
    "        FROM type_coerce\n",
    "        EXCLUDE ({', '.join([c + '_raw' for c in LIST_STRING_COLS])}, characters_raw)\n",
    "    ),\n",
    "    \n",
    "    -- Step 6a: SpecialFillTransformer - ffill for startYear\n",
    "    ffill_start_year AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            -- Replicate pandas ffill() using window function, ordered by implicit row ID\n",
    "            LAG(startYear, 1) IGNORE NULLS OVER (ORDER BY _row_id) AS startYear_ffilled\n",
    "        FROM clean_lists_json\n",
    "    ),\n",
    "\n",
    "    -- Step 6b: SpecialFillTransformer - All other fills\n",
    "    special_fills AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            -- 1. Fill startYear: ffill + median fallback\n",
    "            COALESCE(startYear, startYear_ffilled, (SELECT median_start_year FROM settings)) AS startYear_filled,\n",
    "\n",
    "            -- 2. Zero-fill columns\n",
    "            {', '.join([sql_zero_fill(c) for c in ZERO_FILL_COLS])},\n",
    "\n",
    "            -- 3. Normalize isAdult\n",
    "            COALESCE(CASE WHEN lower(trim(isAdult_raw::VARCHAR)) IN ('1', 'true', 't') THEN 1 ELSE 0 END, 0) AS isAdult\n",
    "\n",
    "        FROM ffill_start_year\n",
    "        -- Exclude raw/intermediate columns\n",
    "        EXCLUDE (startYear, startYear_ffilled, isAdult_raw, {', '.join(ZERO_FILL_COLS)})\n",
    "    ),\n",
    "    \n",
    "    -- Step 6c: Fix endYear < startYear\n",
    "    fix_end_year AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            CASE\n",
    "                WHEN endYear != 0 AND endYear < startYear_filled\n",
    "                THEN startYear_filled\n",
    "                ELSE endYear\n",
    "            END AS endYear_fixed\n",
    "        FROM special_fills\n",
    "        EXCLUDE (endYear) -- drop old endYear\n",
    "    ),\n",
    "\n",
    "    -- Step 7: LeftoverNullFiller and final column selection\n",
    "    final_cleaned AS (\n",
    "        SELECT\n",
    "            -- Select all cleaned columns in desired order\n",
    "            tconst,\n",
    "            primaryTitle,\n",
    "            originalTitle,\n",
    "            genres,\n",
    "            directors,\n",
    "            writers,\n",
    "            characters,\n",
    "            startYear_filled AS startYear,\n",
    "            endYear_fixed AS endYear,\n",
    "            runtimeMinutes,\n",
    "            isAdult,\n",
    "            titleType,\n",
    "            primaryName,\n",
    "            birthYear,\n",
    "            deathYear,\n",
    "            primaryProfession,\n",
    "            knownForTitles,\n",
    "            averageRating,\n",
    "            numVotes,\n",
    "            seasonNumber,\n",
    "            episodeNumber,\n",
    "            region,\n",
    "            language,\n",
    "            types,\n",
    "            category,\n",
    "\n",
    "            -- Fill leftovers\n",
    "            {', '.join([sql_leftover_string(c) for c in LEFTOVER_STRING_COLS])},\n",
    "            {', '.join([sql_leftover_numeric(c) for c in LEFTOVER_NUMERIC_COLS])}\n",
    "\n",
    "        FROM fix_end_year\n",
    "    )\n",
    "    \n",
    "    -- === 4️⃣ Save to CSV ===\n",
    "    COPY (SELECT * FROM final_cleaned) TO '{output_csv}' (HEADER, DELIMITER ',');\n",
    "    \"\"\"\n",
    "    \n",
    "    return query\n",
    "\n",
    "# === 5️⃣ Execute the pipeline ===\n",
    "con = None\n",
    "try:\n",
    "    # Connect to an in-memory database\n",
    "    con = duckdb.connect(database=':memory:')\n",
    "    print(\"DuckDB connection established.\")\n",
    "    \n",
    "    # Build the full query\n",
    "    full_query = build_cleaning_query(FILE_URL, OUTPUT_FILE_CSV)\n",
    "    \n",
    "    # print(full_query) # Uncomment to debug the generated SQL\n",
    "    \n",
    "    print(\"Starting cleaning pipeline...\")\n",
    "    con.execute(full_query)\n",
    "    print(\"✅ Cleaning pipeline complete.\")\n",
    "    \n",
    "    print(f\"\\n💾 Cleaned CSV saved as: {OUTPUT_FILE_CSV}\")\n",
    "\n",
    "    # === 6️⃣ Check results ===\n",
    "    print(\"\\n--- Sample rows (post-cleaning) ---\")\n",
    "    con.execute(\"SELECT * FROM final_cleaned LIMIT 10\").df().info()\n",
    "    print(con.execute(\"SELECT * FROM final_cleaned LIMIT 10\").df())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\", file=sys.stderr)\n",
    "finally:\n",
    "    if con:\n",
    "        con.close()\n",
    "        print(\"DuckDB connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f717c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This reads the Parquet file and returns a Pandas DataFrame\n",
    "df = pd.read_parquet('https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-25_165557_UTC/imdb_cleaned_for_colleagues.parquet')\n",
    "\n",
    "# You can specify the engine, though 'auto' (default) usually works fine:\n",
    "# df = pd.read_parquet('your_file_name.parquet', engine='pyarrow')\n",
    "\n",
    "# To read only a subset of columns (efficiently!):\n",
    "# df = pd.read_parquet('your_file_name.parquet', columns=['col1', 'col2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbcac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 34 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   startYear          100000 non-null  float64\n",
      " 1   endYear            100000 non-null  float64\n",
      " 2   runtimeMinutes     100000 non-null  float64\n",
      " 3   averageRating      100000 non-null  float64\n",
      " 4   numVotes           100000 non-null  float64\n",
      " 5   seasonNumber       100000 non-null  float64\n",
      " 6   episodeNumber      100000 non-null  float64\n",
      " 7   birthYear          100000 non-null  float64\n",
      " 8   deathYear          100000 non-null  float64\n",
      " 9   titleType          100000 non-null  object \n",
      " 10  isAdult            100000 non-null  int64  \n",
      " 11  region             79036 non-null   object \n",
      " 12  language           64190 non-null   object \n",
      " 13  types              33852 non-null   object \n",
      " 14  category           99111 non-null   object \n",
      " 15  tconst             100000 non-null  object \n",
      " 16  primaryTitle       100000 non-null  object \n",
      " 17  originalTitle      100000 non-null  object \n",
      " 18  genres             100000 non-null  object \n",
      " 19  directors          100000 non-null  object \n",
      " 20  writers            100000 non-null  object \n",
      " 21  parentTconst       78252 non-null   object \n",
      " 22  titleId            99987 non-null   object \n",
      " 23  ordering           99987 non-null   float64\n",
      " 24  title              99987 non-null   object \n",
      " 25  isOriginalTitle    99987 non-null   float64\n",
      " 26  tconst_1           99111 non-null   object \n",
      " 27  ordering_1         99111 non-null   float64\n",
      " 28  nconst             99111 non-null   object \n",
      " 29  characters         100000 non-null  object \n",
      " 30  nconst_1           99093 non-null   object \n",
      " 31  primaryName        100000 non-null  object \n",
      " 32  primaryProfession  100000 non-null  object \n",
      " 33  knownForTitles     100000 non-null  object \n",
      "dtypes: float64(12), int64(1), object(21)\n",
      "memory usage: 25.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb_clean_final_by_rules.py\n",
    "# Run in your Azure notebook cell. Adjust INPUT_URL and OUTPUT_PQ if needed.\n",
    "\n",
    "import duckdb\n",
    "import math\n",
    "from pprint import pprint\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "INPUT_URL = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-22_105430_UTC/imdb_merged_duckdb.parquet\"\n",
    "OUTPUT_PQ = \"imdb_cleaned_final_by_rules.parquet\"\n",
    "TEXT_FILL = \"unknown\"\n",
    "# Columns to drop per your decision\n",
    "DROP_COLS = {\"endYear\", \"deathYear\", \"attributes\", \"job\", \"averageRating\", \"numVotes\"}\n",
    "# Columns considered list-like\n",
    "LIST_COLS = {\"genres\", \"directors\", \"writers\", \"primaryProfession\", \"knownForTitles\"}\n",
    "CHAR_COLS = {\"characters\"}\n",
    "# Numeric columns to impute with median\n",
    "NUMERIC_IMPUTE_COLS = [\"startYear\", \"runtimeMinutes\", \"seasonNumber\", \"episodeNumber\", \"birthYear\"]\n",
    "# ----------------------------------------\n",
    "\n",
    "def q(col: str) -> str:\n",
    "    # safe quoting for identifiers\n",
    "    return '\"' + col.replace('\"', '\"\"') + '\"'\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# optional: limit threads in shared kernel\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=2;\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Registering parquet as view: imdb_raw\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW imdb_raw AS SELECT * FROM read_parquet('{INPUT_URL}');\")\n",
    "\n",
    "# Inspect schema\n",
    "cols_info = con.execute(\"DESCRIBE imdb_raw\").fetchall()\n",
    "print(f\"Detected {len(cols_info)} columns.\")\n",
    "pprint(cols_info[:40])\n",
    "\n",
    "# Compute medians for numeric impute candidates (TRY_CAST to double)\n",
    "medians = {}\n",
    "for col in NUMERIC_IMPUTE_COLS:\n",
    "    try:\n",
    "        sql = f\"\"\"\n",
    "        SELECT percentile_cont(0.5) WITHIN GROUP (ORDER BY TRY_CAST({q(col)} AS DOUBLE))\n",
    "        FROM imdb_raw\n",
    "        WHERE TRY_CAST({q(col)} AS DOUBLE) IS NOT NULL\n",
    "        \"\"\"\n",
    "        res = con.execute(sql).fetchone()\n",
    "        med = res[0] if res and res[0] is not None else 0.0\n",
    "        if med is None or (isinstance(med, float) and (math.isnan(med) or math.isinf(med))):\n",
    "            med = 0.0\n",
    "    except Exception:\n",
    "        med = 0.0\n",
    "    medians[col] = float(med)\n",
    "\n",
    "print(\"Medians to use for imputation:\")\n",
    "pprint(medians)\n",
    "\n",
    "# Build select parts following rules\n",
    "select_parts = []\n",
    "for col, coltype in cols_info:\n",
    "    # skip dropped columns\n",
    "    if col in DROP_COLS:\n",
    "        print(f\" -> Dropping column: {col}\")\n",
    "        continue\n",
    "\n",
    "    # characters: clean JSON-like arrays -> empty string if missing\n",
    "    if col in CHAR_COLS:\n",
    "        select_parts.append(\n",
    "            f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' OR trim({q(col)}) = '' THEN '' \"\n",
    "            f\"ELSE lower(regexp_replace(regexp_replace(regexp_replace({q(col)}, '\\\\\\\\[|\\\\\\\\]|\\\"', '', 'g'), '\\\\\\\\s*,\\\\\\\\s*', ',', 'g'), '^,+|,+$', '', 'g')) END AS {q(col)}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # list-like columns: normalize commas, lowercase, fill 'unknown' when missing\n",
    "    if col in LIST_COLS:\n",
    "        select_parts.append(\n",
    "            f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' OR trim({q(col)}) = '' THEN '{TEXT_FILL}' \"\n",
    "            f\"ELSE lower(regexp_replace(regexp_replace({q(col)}, '\\\\\\\\s*,\\\\\\\\s*', ',', 'g'), '^,+|,+$', '', 'g')) END AS {q(col)}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # isAdult -> ensure 0/1 integer\n",
    "    if col == \"isAdult\":\n",
    "        # treat 'true'/'false' or numeric; fallback to 0\n",
    "        select_parts.append(\n",
    "            f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' THEN 0 \"\n",
    "            f\"WHEN lower(trim(CAST({q(col)} AS VARCHAR))) IN ('1','true','t','yes') THEN 1 ELSE 0 END AS {q(col)}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # numeric imputation for chosen numeric columns\n",
    "    if col in medians:\n",
    "        med = medians[col]\n",
    "        # treat year-like and count-like as BIGINT\n",
    "        if col.lower().endswith(\"year\") or col.lower().endswith(\"number\") or 'season' in col.lower() or 'episode' in col.lower():\n",
    "            select_parts.append(f\"COALESCE(TRY_CAST({q(col)} AS BIGINT), {int(med)}) AS {q(col)}\")\n",
    "        else:\n",
    "            select_parts.append(f\"COALESCE(TRY_CAST({q(col)} AS DOUBLE), {float(med)}) AS {q(col)}\")\n",
    "        continue\n",
    "\n",
    "    # For any remaining column: treat text as 'unknown' when missing; lowercase/trim\n",
    "    # If column is numeric-like (declared), try to cast; else fallback to text handling\n",
    "    declared_type = (coltype or \"\").lower()\n",
    "    if any(t in declared_type for t in [\"tinyint\",\"smallint\",\"integer\",\"int\",\"bigint\",\"decimal\",\"numeric\",\"float\",\"double\",\"real\"]):\n",
    "        # numeric declared but not in medians list -> coerce to double and coalesce to 0\n",
    "        select_parts.append(f\"COALESCE(TRY_CAST({q(col)} AS DOUBLE), 0) AS {q(col)}\")\n",
    "    else:\n",
    "        select_parts.append(\n",
    "            f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' OR trim({q(col)}) = '' THEN '{TEXT_FILL}' ELSE lower(trim({q(col)})) END AS {q(col)}\"\n",
    "        )\n",
    "\n",
    "# Assemble final SQL\n",
    "final_select_sql = \",\\n    \".join(select_parts)\n",
    "create_view_sql = f\"\"\"\n",
    "CREATE OR REPLACE VIEW imdb_cleaned_by_rules_view AS\n",
    "SELECT\n",
    "    {final_select_sql}\n",
    "FROM imdb_raw;\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating view imdb_cleaned_by_rules_view ... (this applies all transforms)\")\n",
    "con.execute(create_view_sql)\n",
    "print(\"View created.\")\n",
    "\n",
    "# Materialize to table and export parquet\n",
    "print(\"Materializing table imdb_cleaned_by_rules ...\")\n",
    "con.execute(\"CREATE OR REPLACE TABLE imdb_cleaned_by_rules AS SELECT * FROM imdb_cleaned_by_rules_view;\")\n",
    "print(\"Exporting to parquet:\", OUTPUT_PQ)\n",
    "con.execute(f\"COPY (SELECT * FROM imdb_cleaned_by_rules) TO '{OUTPUT_PQ}' (FORMAT PARQUET, COMPRESSION 'SNAPPY');\")\n",
    "print(\"Export finished:\", OUTPUT_PQ)\n",
    "\n",
    "# Verification: ensure no NULLs remain (print any columns with non-zero nulls)\n",
    "print(\"Verifying null counts per column...\")\n",
    "cols_after = [c for c, t in cols_info if c not in DROP_COLS]\n",
    "null_exprs = \", \".join([f\"SUM(CASE WHEN {q(c)} IS NULL THEN 1 ELSE 0 END) AS {c}_nulls\" for c in cols_after])\n",
    "nulls_row = con.execute(f\"SELECT {null_exprs} FROM imdb_cleaned_by_rules\").fetchone()\n",
    "nulls_map = {cols_after[i]: nulls_row[i] for i in range(len(cols_after))}\n",
    "total_rows = con.execute(\"SELECT COUNT(*) FROM imdb_cleaned_by_rules\").fetchone()[0]\n",
    "\n",
    "non_zero = {k: v for k, v in nulls_map.items() if v and v > 0}\n",
    "if non_zero:\n",
    "    print(\"⚠️ Columns still containing NULLs (unexpected):\")\n",
    "    for k, v in non_zero.items():\n",
    "        pct = v / total_rows * 100 if total_rows > 0 else 0\n",
    "        print(f\" - {k}: {v} nulls ({pct:.4f}%)\")\n",
    "else:\n",
    "    print(\"✅ Success — no NULLs in the materialized table (after applied rules).\")\n",
    "\n",
    "# show a quick sample and some stats for the imputed numeric cols\n",
    "print(\"\\nSample rows:\")\n",
    "print(con.execute(\"SELECT * FROM imdb_cleaned_by_rules LIMIT 10\").fetchdf())\n",
    "\n",
    "print(\"\\nNumeric summary for imputed columns:\")\n",
    "print(con.execute(\"SELECT AVG(startYear) AS avg_startYear, MEDIAN(startYear) AS med_startYear, \"\n",
    "                  \"AVG(runtimeMinutes) AS avg_runtime, MEDIAN(runtimeMinutes) AS med_runtime, \"\n",
    "                  \"AVG(birthYear) AS avg_birthYear, MEDIAN(birthYear) AS med_birthYear \"\n",
    "                  \"FROM imdb_cleaned_by_rules\").fetchdf())\n",
    "\n",
    "con.close()\n",
    "print(\"All done. Output file:\", OUTPUT_PQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2f964",
   "metadata": {},
   "source": [
    "# I do it locally, with the usage of the terminal, but unfortunately the cleaning is poor , and we need to improve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79144113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering parquet view: https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-25_160707_UTC/imdb_sample_100k.parquet\n",
      "Detected 36 columns. Sample:\n",
      "[('tconst', 'VARCHAR'),\n",
      " ('titleType', 'VARCHAR'),\n",
      " ('primaryTitle', 'VARCHAR'),\n",
      " ('originalTitle', 'VARCHAR'),\n",
      " ('isAdult', 'BIGINT'),\n",
      " ('startYear', 'BIGINT'),\n",
      " ('endYear', 'VARCHAR'),\n",
      " ('runtimeMinutes', 'BIGINT'),\n",
      " ('genres', 'VARCHAR'),\n",
      " ('averageRating', 'DOUBLE'),\n",
      " ('numVotes', 'BIGINT'),\n",
      " ('directors', 'VARCHAR'),\n",
      " ('writers', 'VARCHAR'),\n",
      " ('parentTconst', 'VARCHAR'),\n",
      " ('seasonNumber', 'BIGINT'),\n",
      " ('episodeNumber', 'BIGINT'),\n",
      " ('titleId', 'VARCHAR'),\n",
      " ('ordering', 'BIGINT'),\n",
      " ('title', 'VARCHAR'),\n",
      " ('region', 'VARCHAR'),\n",
      " ('language', 'VARCHAR'),\n",
      " ('types', 'VARCHAR'),\n",
      " ('attributes', 'VARCHAR'),\n",
      " ('isOriginalTitle', 'BIGINT'),\n",
      " ('tconst_1', 'VARCHAR'),\n",
      " ('ordering_1', 'BIGINT'),\n",
      " ('nconst', 'VARCHAR'),\n",
      " ('category', 'VARCHAR'),\n",
      " ('job', 'VARCHAR'),\n",
      " ('characters', 'VARCHAR'),\n",
      " ('nconst_1', 'VARCHAR'),\n",
      " ('primaryName', 'VARCHAR'),\n",
      " ('birthYear', 'BIGINT'),\n",
      " ('deathYear', 'BIGINT'),\n",
      " ('primaryProfession', 'VARCHAR'),\n",
      " ('knownForTitles', 'VARCHAR')]\n",
      "Numeric columns to compute medians for: ['isAdult', 'startYear', 'runtimeMinutes', 'averageRating', 'numVotes', 'seasonNumber', 'episodeNumber', 'ordering', 'isOriginalTitle', 'ordering_1', 'birthYear', 'deathYear', 'endYear']\n",
      "Computed medians (numeric defaults):\n",
      "{'averageRating': 6.7,\n",
      " 'birthYear': 1961.0,\n",
      " 'deathYear': 2007.0,\n",
      " 'endYear': 2016.0,\n",
      " 'episodeNumber': 81.0,\n",
      " 'isAdult': 0.0,\n",
      " 'isOriginalTitle': 0.0,\n",
      " 'numVotes': 185.0,\n",
      " 'ordering': 4.0,\n",
      " 'ordering_1': 6.0,\n",
      " 'runtimeMinutes': 45.0,\n",
      " 'seasonNumber': 1.0,\n",
      " 'startYear': 2012.0}\n",
      "CREATE VIEW imdb_cleaned_full (snippet):\n",
      "\n",
      "CREATE OR REPLACE VIEW imdb_cleaned_full AS\n",
      "SELECT\n",
      "    CASE WHEN \"tconst\" IS NULL OR \"tconst\" = '\\\\N' OR trim(\"tconst\") = '' THEN 'unknown' ELSE lower(trim(\"tconst\")) END AS \"tconst\",\n",
      "    CASE WHEN \"titleType\" IS NULL OR \"titleType\" = '\\\\N' OR trim(\"titleType\") = '' THEN 'unknown' ELSE lower(trim(\"titleType\")) END AS \"titleType\",\n",
      "    CASE WHEN \"primaryTitle\" IS NULL OR \"primaryTitle\" = '\\\\N' OR trim(\"primaryTitle\") = '' THEN 'unknown' ELSE lower(trim(\"primaryTitle\")) END AS \"primaryTitle\",\n",
      "    CASE WHEN \"originalTitle\" IS NULL OR \"originalTitle\" = '\\\\N' OR trim(\"originalTitle\") = '' THEN 'unknown' ELSE lower(trim(\"originalTitle\")) END AS \"originalTitle\",\n",
      "    COALESCE(TRY_CAST(\"isAdult\" AS DOUBLE), 0.0) AS \"isAdult\",\n",
      "    COALESCE(TRY_CAST(\"startYear\" AS BIGINT), 2012) AS \"startYear\",\n",
      "    COALESCE(TRY_CAST(\"endYear\" AS BIGINT), 2016) AS \"endYear\",\n",
      "    COALESCE(TRY_CAST(\"runtimeMinutes\" AS DOUBLE), 45.0) AS \"runtimeMinutes\",\n",
      "    CASE WHEN \"genres\" IS NULL OR \"genres\" = '\\\\N' OR trim(\"genres\") = '' THEN 'unknown' ELSE lower(regexp_replace(regexp_replace(\"genres\", '\\\\s*,\\\\s*', ',', 'g'), '^,+|,+$', '', 'g')) END AS \"genres\",\n",
      "    COALESCE(TRY_CAST(\"averageRating\" AS DOUBLE), 6.7) AS \"av\n",
      "View imdb_cleaned_full created.\n",
      "Creating table imdb_no_nulls (materialized) ...\n",
      "Table imdb_no_nulls created. Now exporting to Parquet: imdb_merged_cleaned_duckdb.parquet\n",
      "Export complete: imdb_merged_cleaned_duckdb.parquet\n",
      "Verifying null counts for every column...\n",
      "Columns with non-zero null counts (should be empty):\n",
      "✅ Success — absolutely no nulls found in imdb_no_nulls table.\n"
     ]
    }
   ],
   "source": [
    "# duckdb_full_clean_no_nulls.py\n",
    "# Run in your Azure kernel cell. Adjust INPUT_URL and OUTPUT_PATH as needed.\n",
    "\n",
    "import duckdb\n",
    "import math\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# -------------- CONFIG --------------\n",
    "INPUT_URL = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-25_160707_UTC/imdb_sample_100k.parquet\"   # change to your sample or the real parquet path/URL\n",
    "OUTPUT_PARQUET = \"imdb_merged_cleaned_duckdb.parquet\"\n",
    "# Columns that you know should be treated as list-like or JSON-like (customize if needed)\n",
    "LIST_COLS = {'genres', 'directors', 'writers', 'primaryProfession', 'knownForTitles'}\n",
    "CHAR_COLS = {'characters'}   # JSON-like arrays stored as strings\n",
    "# Safe text default:\n",
    "TEXT_FILL = \"unknown\"\n",
    "# ------------------------------------\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Limit threads if you're inside a constrained Azure shared kernel (optional)\n",
    "try:\n",
    "    con.execute(\"PRAGMA threads=2;\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Registering parquet view:\", INPUT_URL)\n",
    "# Create a view on the parquet file so we can query it without loading into memory\n",
    "con.execute(f\"CREATE OR REPLACE VIEW imdb_raw AS SELECT * FROM read_parquet('{INPUT_URL}');\")\n",
    "\n",
    "# Inspect schema\n",
    "cols_info = con.execute(\"DESCRIBE imdb_raw\").fetchall()\n",
    "all_cols = [(r[0], r[1]) for r in cols_info]\n",
    "print(f\"Detected {len(all_cols)} columns. Sample:\")\n",
    "pprint(all_cols[:40])\n",
    "\n",
    "# Helper to quote identifiers safely\n",
    "def q(col):\n",
    "    return '\"' + col.replace('\"', '\"\"') + '\"'\n",
    "\n",
    "# Basic duckdb type heuristics\n",
    "def is_numeric_type(duck_type: str):\n",
    "    t = (duck_type or \"\").lower()\n",
    "    return any(x in t for x in [\"tinyint\",\"smallint\",\"integer\",\"int\",\"bigint\",\"decimal\",\"numeric\",\"float\",\"double\",\"real\"])\n",
    "\n",
    "def is_string_type(duck_type: str):\n",
    "    t = (duck_type or \"\").lower()\n",
    "    return any(x in t for x in [\"varchar\",\"text\",\"string\",\"char\"])\n",
    "\n",
    "# -----------------------\n",
    "# 1) Compute medians for numeric-ish columns (using TRY_CAST)\n",
    "# -----------------------\n",
    "numeric_candidates = [col for col, typ in all_cols if is_numeric_type(typ) or col in LIST_COLS or col in CHAR_COLS or True]\n",
    "# We'll determine numeric columns more strictly below; safer to check all declared numeric-like\n",
    "numeric_cols = [col for col, typ in all_cols if is_numeric_type(typ)]\n",
    "# But sometimes numeric columns are strings in the file (e.g. 'numVotes' typed as varchar) -> detect common-numeric names\n",
    "possible_numeric_by_name = {'numVotes','averageRating','runtimeMinutes','startYear','endYear','birthYear','deathYear','seasonNumber','episodeNumber'}\n",
    "for col, typ in all_cols:\n",
    "    if col in possible_numeric_by_name and col not in numeric_cols:\n",
    "        numeric_cols.append(col)\n",
    "\n",
    "numeric_cols = list(dict.fromkeys(numeric_cols))  # unique and keep order\n",
    "print(\"Numeric columns to compute medians for:\", numeric_cols)\n",
    "\n",
    "medians = {}\n",
    "for col in numeric_cols:\n",
    "    try:\n",
    "        # Try computing median based on values that successfully cast to double\n",
    "        sql = f\"\"\"\n",
    "        SELECT percentile_cont(0.5) WITHIN GROUP (ORDER BY TRY_CAST({q(col)} AS DOUBLE))\n",
    "        FROM imdb_raw\n",
    "        WHERE TRY_CAST({q(col)} AS DOUBLE) IS NOT NULL\n",
    "        \"\"\"\n",
    "        res = con.execute(sql).fetchone()\n",
    "        med = res[0] if res and res[0] is not None else 0.0\n",
    "        if med is None or (isinstance(med, float) and (math.isnan(med) or math.isinf(med))):\n",
    "            med = 0.0\n",
    "    except Exception:\n",
    "        med = 0.0\n",
    "    medians[col] = float(med)\n",
    "print(\"Computed medians (numeric defaults):\")\n",
    "pprint(medians)\n",
    "\n",
    "# -----------------------\n",
    "# 2) Build safe SELECT expressions for every column (explicit)\n",
    "# -----------------------\n",
    "select_parts = []\n",
    "for col, coltype in all_cols:\n",
    "    if col in LIST_COLS:\n",
    "        # Normalize list strings (lower, trim spaces around commas), replace '\\N' or NULL with TEXT_FILL\n",
    "        # We keep TEXT_FILL (unknown) for lists too per requirement of no nulls\n",
    "        if is_string_type(coltype):\n",
    "            expr = f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' OR trim({q(col)}) = '' THEN '{TEXT_FILL}' ELSE lower(regexp_replace(regexp_replace({q(col)}, '\\\\\\\\s*,\\\\\\\\s*', ',', 'g'), '^,+|,+$', '', 'g')) END AS {q(col)}\"\n",
    "        else:\n",
    "            # If underlying type is not string, cast to VARCHAR first\n",
    "            expr = f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' THEN '{TEXT_FILL}' WHEN TRY_CAST({q(col)} AS DOUBLE) IS NOT NULL THEN lower(regexp_replace(regexp_replace(CAST(TRY_CAST({q(col)} AS DOUBLE) AS VARCHAR), '\\\\\\\\s*,\\\\\\\\s*', ',', 'g'), '^,+|,+$', '', 'g')) ELSE '{TEXT_FILL}' END AS {q(col)}\"\n",
    "        select_parts.append(expr)\n",
    "        continue\n",
    "\n",
    "    if col in CHAR_COLS:\n",
    "        # remove [ ] \" characters and normalize commas, fallback to empty string (or TEXT_FILL if you prefer)\n",
    "        if is_string_type(coltype):\n",
    "            expr = f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' OR trim({q(col)}) = '' THEN '' ELSE lower(regexp_replace(regexp_replace(regexp_replace({q(col)}, '\\\\\\\\[|\\\\\\\\]|\\\"', '', 'g'), '\\\\\\\\s*,\\\\\\\\s*', ',', 'g'), '^,+|,+$', '', 'g')) END AS {q(col)}\"\n",
    "        else:\n",
    "            expr = f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' THEN '' WHEN TRY_CAST({q(col)} AS DOUBLE) IS NOT NULL THEN lower(regexp_replace(regexp_replace(regexp_replace(CAST(TRY_CAST({q(col)} AS DOUBLE) AS VARCHAR), '\\\\\\\\[|\\\\\\\\]|\\\"', '', 'g'), '\\\\\\\\s*,\\\\\\\\s*', ',', 'g'), '^,+|,+$', '', 'g')) ELSE '' END AS {q(col)}\"\n",
    "        select_parts.append(expr)\n",
    "        continue\n",
    "\n",
    "    # Numeric handling: TRY_CAST to double, COALESCE to median default\n",
    "    if col in medians:\n",
    "        med = medians[col]\n",
    "        # If column looks like integer (year like) keep BIGINT cast else double\n",
    "        if col.lower().endswith(\"year\") or col.lower().endswith(\"number\") or 'season' in col.lower() or 'episode' in col.lower() or col.lower().endswith('votes'):\n",
    "            # use BIGINT / integer fallback where possible\n",
    "            expr = f\"COALESCE(TRY_CAST({q(col)} AS BIGINT), {int(med)}) AS {q(col)}\"\n",
    "        else:\n",
    "            expr = f\"COALESCE(TRY_CAST({q(col)} AS DOUBLE), {float(med)}) AS {q(col)}\"\n",
    "        select_parts.append(expr)\n",
    "        continue\n",
    "\n",
    "    # For declared string columns -> replace '\\N' and null/empty with TEXT_FILL\n",
    "    if is_string_type(coltype):\n",
    "        expr = f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' OR trim({q(col)}) = '' THEN '{TEXT_FILL}' ELSE lower(trim({q(col)})) END AS {q(col)}\"\n",
    "        select_parts.append(expr)\n",
    "        continue\n",
    "\n",
    "    # Fallback: try casting to double, else treat as text\n",
    "    expr = (f\"CASE WHEN {q(col)} IS NULL OR {q(col)} = '\\\\\\\\N' THEN '{TEXT_FILL}' \"\n",
    "            f\"WHEN TRY_CAST({q(col)} AS DOUBLE) IS NOT NULL THEN TRY_CAST({q(col)} AS DOUBLE) ELSE '{TEXT_FILL}' END AS {q(col)}\")\n",
    "    select_parts.append(expr)\n",
    "\n",
    "# Final assembled SQL\n",
    "final_select_sql = \",\\n    \".join(select_parts)\n",
    "create_view_sql = f\"\"\"\n",
    "CREATE OR REPLACE VIEW imdb_cleaned_full AS\n",
    "SELECT\n",
    "    {final_select_sql}\n",
    "FROM imdb_raw;\n",
    "\"\"\"\n",
    "# Debug: show first 1200 chars to sanity-check\n",
    "print(\"CREATE VIEW imdb_cleaned_full (snippet):\")\n",
    "print(create_view_sql[:1200])\n",
    "\n",
    "# -----------------------\n",
    "# 3) Execute view creation\n",
    "# -----------------------\n",
    "con.execute(create_view_sql)\n",
    "print(\"View imdb_cleaned_full created.\")\n",
    "\n",
    "# -----------------------\n",
    "# 4) Materialize (create table) and export to Parquet (streamed)\n",
    "# -----------------------\n",
    "# Materialize to a table so we can run verification queries quickly\n",
    "print(\"Creating table imdb_no_nulls (materialized) ...\")\n",
    "con.execute(\"CREATE OR REPLACE TABLE imdb_no_nulls AS SELECT * FROM imdb_cleaned_full;\")\n",
    "print(\"Table imdb_no_nulls created. Now exporting to Parquet:\", OUTPUT_PARQUET)\n",
    "con.execute(f\"COPY (SELECT * FROM imdb_no_nulls) TO '{OUTPUT_PARQUET}' (FORMAT PARQUET, COMPRESSION 'SNAPPY');\")\n",
    "print(\"Export complete:\", OUTPUT_PARQUET)\n",
    "\n",
    "# -----------------------\n",
    "# 5) VERIFY: ensure ZERO NULLS across all columns\n",
    "# -----------------------\n",
    "print(\"Verifying null counts for every column...\")\n",
    "cols = [c for c, t in all_cols]\n",
    "\n",
    "# Build null count expressions safely (avoid alias quoting issues)\n",
    "null_exprs = \",\\n\".join([\n",
    "    f\"SUM(CASE WHEN {q(col)} IS NULL THEN 1 ELSE 0 END) AS {col}_nulls\"\n",
    "    for col in cols\n",
    "])\n",
    "nulls_sql = f\"SELECT {null_exprs} FROM imdb_no_nulls;\"\n",
    "\n",
    "nulls_row = con.execute(nulls_sql).fetchone()\n",
    "\n",
    "# Create mapping col -> null count\n",
    "nulls_map = {cols[i]: nulls_row[i] for i in range(len(cols))}\n",
    "non_zero = {k: v for k, v in nulls_map.items() if v and v > 0}\n",
    "\n",
    "print(\"Columns with non-zero null counts (should be empty):\")\n",
    "if non_zero:\n",
    "    for k, v in non_zero.items():\n",
    "        print(f\"❌ {k}: {v}\")\n",
    "else:\n",
    "    print(\"✅ Success — absolutely no nulls found in imdb_no_nulls table.\")\n",
    "\n",
    "# Close connection\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee1c23",
   "metadata": {},
   "source": [
    "# Some random overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf1c480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rows (limit 20):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>...</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "      <th>nconst_1</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt17755732</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.210</td>\n",
       "      <td>episode #1.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2016</td>\n",
       "      <td>54.0</td>\n",
       "      <td>drama,fantasy,romance</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm12909343</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[citra marisca]</td>\n",
       "      <td>nm12909343</td>\n",
       "      <td>harini sondakh</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>actress</td>\n",
       "      <td>tt15368302,tt13984562,tt28590286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt34507138</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.335</td>\n",
       "      <td>episode #1.335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>drama,romance</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm4137808</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm4137808</td>\n",
       "      <td>rajeev parameshwar</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt3605606,tt2796978,tt1754332,tt10189448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0207871</td>\n",
       "      <td>tvseries</td>\n",
       "      <td>buccaneer</td>\n",
       "      <td>buccaneer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>2016</td>\n",
       "      <td>50.0</td>\n",
       "      <td>adventure,drama</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0204096</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[accountant]</td>\n",
       "      <td>nm0204096</td>\n",
       "      <td>geoffrey davion</td>\n",
       "      <td>1940</td>\n",
       "      <td>1996</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt0087749,tt0072566,tt0090852,tt0065290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt28210850</td>\n",
       "      <td>short</td>\n",
       "      <td>howdy, comrade!</td>\n",
       "      <td>howdy, comrade!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2016</td>\n",
       "      <td>6.0</td>\n",
       "      <td>comedy,short</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm12859469</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td></td>\n",
       "      <td>nm12859469</td>\n",
       "      <td>jax maloney</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>actor,writer,director</td>\n",
       "      <td>tt28054598,tt20223646,tt32573807,tt15741906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt7121444</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.149</td>\n",
       "      <td>episode #1.149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1994</td>\n",
       "      <td>2016</td>\n",
       "      <td>60.0</td>\n",
       "      <td>drama,romance</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1018021</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td></td>\n",
       "      <td>nm1018021</td>\n",
       "      <td>maría josé fuentebuena</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>producer,miscellaneous</td>\n",
       "      <td>tt0396300,tt0227896,tt6556846,tt10971476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt9188364</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.29</td>\n",
       "      <td>episode #1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1387873</td>\n",
       "      <td>director</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm1387873</td>\n",
       "      <td>darnel villaflor</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>director,miscellaneous,producer</td>\n",
       "      <td>tt12275096,tt8528294,tt1836451,tt16154940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tt27803650</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #5.115</td>\n",
       "      <td>episode #5.115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>2016</td>\n",
       "      <td>180.0</td>\n",
       "      <td>reality-tv</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm14860922</td>\n",
       "      <td>director</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm14860922</td>\n",
       "      <td>alessio pollacci</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>director</td>\n",
       "      <td>tt6078678,tt0261474,tt36895482,tt31109465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tt29929538</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #3.16</td>\n",
       "      <td>episode #3.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>animation,family</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1997137</td>\n",
       "      <td>writer</td>\n",
       "      <td>writer</td>\n",
       "      <td></td>\n",
       "      <td>nm1997137</td>\n",
       "      <td>franck salomé</td>\n",
       "      <td>1965</td>\n",
       "      <td>2007</td>\n",
       "      <td>writer,director</td>\n",
       "      <td>tt0878817,tt0804234,tt9636800,tt0414746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tt1418612</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 17 april 2009</td>\n",
       "      <td>episode dated 17 april 2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>news,talk-show</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0787754</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[self - film critic]</td>\n",
       "      <td>nm0787754</td>\n",
       "      <td>gene shalit</td>\n",
       "      <td>1926</td>\n",
       "      <td>2007</td>\n",
       "      <td>actor,writer,archive_footage</td>\n",
       "      <td>tt0165042,tt0057758,tt0080249,tt0108734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tt10603930</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.49</td>\n",
       "      <td>episode #1.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>romance</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm10757708</td>\n",
       "      <td>writer</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm10757708</td>\n",
       "      <td>krish jagarlamudi</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>writer,producer</td>\n",
       "      <td>tt31925699,tt3667404,tt20836266,tt12234738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tt31501058</td>\n",
       "      <td>short</td>\n",
       "      <td>maarwat</td>\n",
       "      <td>maarwat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>drama,short</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm9182331</td>\n",
       "      <td>editor</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm9182331</td>\n",
       "      <td>kaustubh bhonge</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>editor,editorial_department,producer</td>\n",
       "      <td>tt31124686,tt14420552,tt11742184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tt11842760</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.1698</td>\n",
       "      <td>episode #1.1698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>crime</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm2223371</td>\n",
       "      <td>cinematographer</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm2223371</td>\n",
       "      <td>shakil b. khan</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>cinematographer</td>\n",
       "      <td>tt1943898,tt6792644,tt1612573,tt36104707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tt33438052</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.2303</td>\n",
       "      <td>episode #1.2303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>2016</td>\n",
       "      <td>30.0</td>\n",
       "      <td>news</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm16276868</td>\n",
       "      <td>self</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[self - newscaster]</td>\n",
       "      <td>nm16276868</td>\n",
       "      <td>norm brewer</td>\n",
       "      <td>1934</td>\n",
       "      <td>2010</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt33384753,tt33447764,tt32188722,tt32646694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tt3368622</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>life's a beach 1</td>\n",
       "      <td>life's a beach 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>family,game-show</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0181656</td>\n",
       "      <td>director</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm0181656</td>\n",
       "      <td>mark corwin</td>\n",
       "      <td>1948</td>\n",
       "      <td>2013</td>\n",
       "      <td>director,assistant_director,producer</td>\n",
       "      <td>tt0072584,tt0110398,tt0170736,tt0096714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tt0118694</td>\n",
       "      <td>movie</td>\n",
       "      <td>in the mood for love</td>\n",
       "      <td>fa yeung nin wah</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2016</td>\n",
       "      <td>98.0</td>\n",
       "      <td>drama,romance</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0001041</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[su li-zhen - mrs. chan]</td>\n",
       "      <td>nm0001041</td>\n",
       "      <td>maggie cheung</td>\n",
       "      <td>1964</td>\n",
       "      <td>2007</td>\n",
       "      <td>actress,soundtrack,archive_footage</td>\n",
       "      <td>tt0118694,tt0299977,tt0101258,tt0117905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tt3346510</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode dated 3 december 2013</td>\n",
       "      <td>episode dated 3 december 2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>talk-show</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1171817</td>\n",
       "      <td>composer</td>\n",
       "      <td>main title composer</td>\n",
       "      <td></td>\n",
       "      <td>nm1171817</td>\n",
       "      <td>brandon christy</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>composer,music_department,actor</td>\n",
       "      <td>tt0800039,tt0405325,tt0494652,tt0422778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tt6144822</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>we're getting a closer look at the places our ...</td>\n",
       "      <td>we're getting a closer look at the places our ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>news,talk-show</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm3080010</td>\n",
       "      <td>actor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[announcer]</td>\n",
       "      <td>nm3080010</td>\n",
       "      <td>mike goral</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>actor</td>\n",
       "      <td>tt2191819,tt3261504,tt1358296,tt2313114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tt4150324</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>episode #1.4956</td>\n",
       "      <td>episode #1.4956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>crime,drama,romance</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>nm0103544</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[tina carter]</td>\n",
       "      <td>nm0103544</td>\n",
       "      <td>luisa bradshaw-white</td>\n",
       "      <td>1974</td>\n",
       "      <td>2007</td>\n",
       "      <td>actress,soundtrack,archive_footage</td>\n",
       "      <td>tt0115390,tt0184122,tt0088512,tt0203248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tt13586826</td>\n",
       "      <td>tvepisode</td>\n",
       "      <td>allumer le camping</td>\n",
       "      <td>allumer le camping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>comedy</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>nm7032070</td>\n",
       "      <td>actress</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[audrey dukor]</td>\n",
       "      <td>nm7032070</td>\n",
       "      <td>candiie</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007</td>\n",
       "      <td>actress,writer</td>\n",
       "      <td>tt0832440,tt15710992,tt11502554,tt8304664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tt2226407</td>\n",
       "      <td>movie</td>\n",
       "      <td>the landlords</td>\n",
       "      <td>padroni di casa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2016</td>\n",
       "      <td>90.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>nm1600173</td>\n",
       "      <td>composer</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>nm1600173</td>\n",
       "      <td>cesare cremonini</td>\n",
       "      <td>1980</td>\n",
       "      <td>2007</td>\n",
       "      <td>composer,actor,writer</td>\n",
       "      <td>tt2226407,tt2039331,tt0813681,tt0306458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tconst  titleType                                       primaryTitle  \\\n",
       "0   tt17755732  tvepisode                                     episode #1.210   \n",
       "1   tt34507138  tvepisode                                     episode #1.335   \n",
       "2    tt0207871   tvseries                                          buccaneer   \n",
       "3   tt28210850      short                                    howdy, comrade!   \n",
       "4    tt7121444  tvepisode                                     episode #1.149   \n",
       "5    tt9188364  tvepisode                                      episode #1.29   \n",
       "6   tt27803650  tvepisode                                     episode #5.115   \n",
       "7   tt29929538  tvepisode                                      episode #3.16   \n",
       "8    tt1418612  tvepisode                        episode dated 17 april 2009   \n",
       "9   tt10603930  tvepisode                                      episode #1.49   \n",
       "10  tt31501058      short                                            maarwat   \n",
       "11  tt11842760  tvepisode                                    episode #1.1698   \n",
       "12  tt33438052  tvepisode                                    episode #1.2303   \n",
       "13   tt3368622  tvepisode                                   life's a beach 1   \n",
       "14   tt0118694      movie                               in the mood for love   \n",
       "15   tt3346510  tvepisode                      episode dated 3 december 2013   \n",
       "16   tt6144822  tvepisode  we're getting a closer look at the places our ...   \n",
       "17   tt4150324  tvepisode                                    episode #1.4956   \n",
       "18  tt13586826  tvepisode                                 allumer le camping   \n",
       "19   tt2226407      movie                                      the landlords   \n",
       "\n",
       "                                        originalTitle  isAdult  startYear  \\\n",
       "0                                      episode #1.210      0.0       2020   \n",
       "1                                      episode #1.335      0.0       2024   \n",
       "2                                           buccaneer      0.0       1980   \n",
       "3                                     howdy, comrade!      0.0       2023   \n",
       "4                                      episode #1.149      0.0       1994   \n",
       "5                                       episode #1.29      0.0       2015   \n",
       "6                                      episode #5.115      0.0       2021   \n",
       "7                                       episode #3.16      0.0       2012   \n",
       "8                         episode dated 17 april 2009      0.0       2009   \n",
       "9                                       episode #1.49      0.0       2013   \n",
       "10                                            maarwat      0.0       2023   \n",
       "11                                    episode #1.1698      0.0       2012   \n",
       "12                                    episode #1.2303      0.0       1968   \n",
       "13                                   life's a beach 1      0.0       2005   \n",
       "14                                   fa yeung nin wah      0.0       2000   \n",
       "15                      episode dated 3 december 2013      0.0       2013   \n",
       "16  we're getting a closer look at the places our ...      0.0       2016   \n",
       "17                                    episode #1.4956      0.0       2014   \n",
       "18                                 allumer le camping      0.0       2020   \n",
       "19                                    padroni di casa      0.0       2012   \n",
       "\n",
       "    endYear  runtimeMinutes                 genres  averageRating  ...  \\\n",
       "0      2016            54.0  drama,fantasy,romance            6.7  ...   \n",
       "1      2016            45.0          drama,romance            6.7  ...   \n",
       "2      2016            50.0        adventure,drama            6.8  ...   \n",
       "3      2016             6.0           comedy,short            6.7  ...   \n",
       "4      2016            60.0          drama,romance            6.7  ...   \n",
       "5      2016            45.0                fantasy            6.7  ...   \n",
       "6      2016           180.0             reality-tv            6.7  ...   \n",
       "7      2016            45.0       animation,family            6.7  ...   \n",
       "8      2016            45.0         news,talk-show            6.7  ...   \n",
       "9      2016            45.0                romance            6.7  ...   \n",
       "10     2016            45.0            drama,short            6.7  ...   \n",
       "11     2016            45.0                  crime            6.7  ...   \n",
       "12     2016            30.0                   news            6.7  ...   \n",
       "13     2016            45.0       family,game-show            6.7  ...   \n",
       "14     2016            98.0          drama,romance            8.0  ...   \n",
       "15     2016            45.0              talk-show            6.7  ...   \n",
       "16     2016            45.0         news,talk-show            6.7  ...   \n",
       "17     2016            45.0    crime,drama,romance            6.7  ...   \n",
       "18     2016            45.0                 comedy            5.4  ...   \n",
       "19     2016            90.0                  drama            6.2  ...   \n",
       "\n",
       "        nconst         category                  job  \\\n",
       "0   nm12909343          actress              unknown   \n",
       "1    nm4137808            actor              unknown   \n",
       "2    nm0204096            actor              unknown   \n",
       "3   nm12859469         producer             producer   \n",
       "4    nm1018021         producer             producer   \n",
       "5    nm1387873         director              unknown   \n",
       "6   nm14860922         director              unknown   \n",
       "7    nm1997137           writer               writer   \n",
       "8    nm0787754             self              unknown   \n",
       "9   nm10757708           writer              unknown   \n",
       "10   nm9182331           editor              unknown   \n",
       "11   nm2223371  cinematographer              unknown   \n",
       "12  nm16276868             self              unknown   \n",
       "13   nm0181656         director              unknown   \n",
       "14   nm0001041          actress              unknown   \n",
       "15   nm1171817         composer  main title composer   \n",
       "16   nm3080010            actor              unknown   \n",
       "17   nm0103544          actress              unknown   \n",
       "18   nm7032070          actress              unknown   \n",
       "19   nm1600173         composer              unknown   \n",
       "\n",
       "                  characters    nconst_1             primaryName birthYear  \\\n",
       "0            [citra marisca]  nm12909343          harini sondakh      1961   \n",
       "1                              nm4137808      rajeev parameshwar      1961   \n",
       "2               [accountant]   nm0204096         geoffrey davion      1940   \n",
       "3                             nm12859469             jax maloney      1961   \n",
       "4                              nm1018021  maría josé fuentebuena      1961   \n",
       "5                              nm1387873        darnel villaflor      1961   \n",
       "6                             nm14860922        alessio pollacci      1961   \n",
       "7                              nm1997137           franck salomé      1965   \n",
       "8       [self - film critic]   nm0787754             gene shalit      1926   \n",
       "9                             nm10757708       krish jagarlamudi      1961   \n",
       "10                             nm9182331         kaustubh bhonge      1961   \n",
       "11                             nm2223371          shakil b. khan      1961   \n",
       "12       [self - newscaster]  nm16276868             norm brewer      1934   \n",
       "13                             nm0181656             mark corwin      1948   \n",
       "14  [su li-zhen - mrs. chan]   nm0001041           maggie cheung      1964   \n",
       "15                             nm1171817         brandon christy      1961   \n",
       "16               [announcer]   nm3080010              mike goral      1961   \n",
       "17             [tina carter]   nm0103544    luisa bradshaw-white      1974   \n",
       "18            [audrey dukor]   nm7032070                 candiie      1961   \n",
       "19                             nm1600173        cesare cremonini      1980   \n",
       "\n",
       "    deathYear                     primaryProfession  \\\n",
       "0        2007                               actress   \n",
       "1        2007                                 actor   \n",
       "2        1996                                 actor   \n",
       "3        2007                 actor,writer,director   \n",
       "4        2007                producer,miscellaneous   \n",
       "5        2007       director,miscellaneous,producer   \n",
       "6        2007                              director   \n",
       "7        2007                       writer,director   \n",
       "8        2007          actor,writer,archive_footage   \n",
       "9        2007                       writer,producer   \n",
       "10       2007  editor,editorial_department,producer   \n",
       "11       2007                       cinematographer   \n",
       "12       2010                                 actor   \n",
       "13       2013  director,assistant_director,producer   \n",
       "14       2007    actress,soundtrack,archive_footage   \n",
       "15       2007       composer,music_department,actor   \n",
       "16       2007                                 actor   \n",
       "17       2007    actress,soundtrack,archive_footage   \n",
       "18       2007                        actress,writer   \n",
       "19       2007                 composer,actor,writer   \n",
       "\n",
       "                                 knownForTitles  \n",
       "0              tt15368302,tt13984562,tt28590286  \n",
       "1      tt3605606,tt2796978,tt1754332,tt10189448  \n",
       "2       tt0087749,tt0072566,tt0090852,tt0065290  \n",
       "3   tt28054598,tt20223646,tt32573807,tt15741906  \n",
       "4      tt0396300,tt0227896,tt6556846,tt10971476  \n",
       "5     tt12275096,tt8528294,tt1836451,tt16154940  \n",
       "6     tt6078678,tt0261474,tt36895482,tt31109465  \n",
       "7       tt0878817,tt0804234,tt9636800,tt0414746  \n",
       "8       tt0165042,tt0057758,tt0080249,tt0108734  \n",
       "9    tt31925699,tt3667404,tt20836266,tt12234738  \n",
       "10             tt31124686,tt14420552,tt11742184  \n",
       "11     tt1943898,tt6792644,tt1612573,tt36104707  \n",
       "12  tt33384753,tt33447764,tt32188722,tt32646694  \n",
       "13      tt0072584,tt0110398,tt0170736,tt0096714  \n",
       "14      tt0118694,tt0299977,tt0101258,tt0117905  \n",
       "15      tt0800039,tt0405325,tt0494652,tt0422778  \n",
       "16      tt2191819,tt3261504,tt1358296,tt2313114  \n",
       "17      tt0115390,tt0184122,tt0088512,tt0203248  \n",
       "18    tt0832440,tt15710992,tt11502554,tt8304664  \n",
       "19      tt2226407,tt2039331,tt0813681,tt0306458  \n",
       "\n",
       "[20 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DESCRIBE imdb_merged_cleaned_duckdb.parquet:\n",
      "[('tconst', 'VARCHAR', 'YES', None, None, None), ('titleType', 'VARCHAR', 'YES', None, None, None), ('primaryTitle', 'VARCHAR', 'YES', None, None, None), ('originalTitle', 'VARCHAR', 'YES', None, None, None), ('isAdult', 'DOUBLE', 'YES', None, None, None), ('startYear', 'BIGINT', 'YES', None, None, None), ('endYear', 'BIGINT', 'YES', None, None, None), ('runtimeMinutes', 'DOUBLE', 'YES', None, None, None), ('genres', 'VARCHAR', 'YES', None, None, None), ('averageRating', 'DOUBLE', 'YES', None, None, None), ('numVotes', 'BIGINT', 'YES', None, None, None), ('directors', 'VARCHAR', 'YES', None, None, None), ('writers', 'VARCHAR', 'YES', None, None, None), ('parentTconst', 'VARCHAR', 'YES', None, None, None), ('seasonNumber', 'BIGINT', 'YES', None, None, None), ('episodeNumber', 'BIGINT', 'YES', None, None, None), ('titleId', 'VARCHAR', 'YES', None, None, None), ('ordering', 'DOUBLE', 'YES', None, None, None), ('title', 'VARCHAR', 'YES', None, None, None), ('region', 'VARCHAR', 'YES', None, None, None), ('language', 'VARCHAR', 'YES', None, None, None), ('types', 'VARCHAR', 'YES', None, None, None), ('attributes', 'VARCHAR', 'YES', None, None, None), ('isOriginalTitle', 'DOUBLE', 'YES', None, None, None), ('tconst_1', 'VARCHAR', 'YES', None, None, None), ('ordering_1', 'DOUBLE', 'YES', None, None, None), ('nconst', 'VARCHAR', 'YES', None, None, None), ('category', 'VARCHAR', 'YES', None, None, None), ('job', 'VARCHAR', 'YES', None, None, None), ('characters', 'VARCHAR', 'YES', None, None, None), ('nconst_1', 'VARCHAR', 'YES', None, None, None), ('primaryName', 'VARCHAR', 'YES', None, None, None), ('birthYear', 'BIGINT', 'YES', None, None, None), ('deathYear', 'BIGINT', 'YES', None, None, None), ('primaryProfession', 'VARCHAR', 'YES', None, None, None), ('knownForTitles', 'VARCHAR', 'YES', None, None, None)]\n",
      "\n",
      "Total rows in view:\n",
      "100000\n",
      "\n",
      "Null counts per column (shows columns with >0 nulls):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [null_count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 30 percent missing (approx):\n",
      "tconst                         | nulls=         0 | pct= 0.000%\n",
      "titleType                      | nulls=         0 | pct= 0.000%\n",
      "primaryTitle                   | nulls=         0 | pct= 0.000%\n",
      "originalTitle                  | nulls=         0 | pct= 0.000%\n",
      "isAdult                        | nulls=         0 | pct= 0.000%\n",
      "startYear                      | nulls=         0 | pct= 0.000%\n",
      "endYear                        | nulls=         0 | pct= 0.000%\n",
      "runtimeMinutes                 | nulls=         0 | pct= 0.000%\n",
      "genres                         | nulls=         0 | pct= 0.000%\n",
      "averageRating                  | nulls=         0 | pct= 0.000%\n",
      "numVotes                       | nulls=         0 | pct= 0.000%\n",
      "directors                      | nulls=         0 | pct= 0.000%\n",
      "writers                        | nulls=         0 | pct= 0.000%\n",
      "parentTconst                   | nulls=         0 | pct= 0.000%\n",
      "seasonNumber                   | nulls=         0 | pct= 0.000%\n",
      "episodeNumber                  | nulls=         0 | pct= 0.000%\n",
      "titleId                        | nulls=         0 | pct= 0.000%\n",
      "ordering                       | nulls=         0 | pct= 0.000%\n",
      "title                          | nulls=         0 | pct= 0.000%\n",
      "region                         | nulls=         0 | pct= 0.000%\n",
      "language                       | nulls=         0 | pct= 0.000%\n",
      "types                          | nulls=         0 | pct= 0.000%\n",
      "attributes                     | nulls=         0 | pct= 0.000%\n",
      "isOriginalTitle                | nulls=         0 | pct= 0.000%\n",
      "tconst_1                       | nulls=         0 | pct= 0.000%\n",
      "ordering_1                     | nulls=         0 | pct= 0.000%\n",
      "nconst                         | nulls=         0 | pct= 0.000%\n",
      "category                       | nulls=         0 | pct= 0.000%\n",
      "job                            | nulls=         0 | pct= 0.000%\n",
      "characters                     | nulls=         0 | pct= 0.000%\n",
      "\n",
      "Non-castable examples for averageRating (up to 50 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averageRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [averageRating]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-castable examples for numVotes (up to 50 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [numVotes]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-castable examples for runtimeMinutes (up to 50 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtimeMinutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [runtimeMinutes]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-castable examples for startYear (up to 50 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [startYear]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import duckdb\n",
    "con = duckdb.connect()\n",
    "\n",
    "# 1) show a quick sample\n",
    "print(\"Sample rows (limit 20):\")\n",
    "display(con.execute(\"SELECT * FROM imdb_merged_cleaned_duckdb.parquet LIMIT 20\").fetchdf())\n",
    "\n",
    "# 2) view schema / types\n",
    "print(\"\\nDESCRIBE imdb_merged_cleaned_duckdb.parquet:\")\n",
    "print(con.execute(\"DESCRIBE imdb_merged_cleaned_duckdb.parquet\").fetchall())\n",
    "\n",
    "# 3) row count\n",
    "print(\"\\nTotal rows in view:\")\n",
    "print(con.execute(\"SELECT COUNT(*) FROM imdb_merged_cleaned_duckdb.parquet\").fetchone()[0])\n",
    "\n",
    "# 4) null counts per column (fast aggregate)\n",
    "print(\"\\nNull counts per column (shows columns with >0 nulls):\")\n",
    "# build query dynamically\n",
    "cols = [row[0] for row in con.execute(\"DESCRIBE imdb_merged_cleaned_duckdb.parquet\").fetchall()]\n",
    "null_exprs = \",\\n\".join([f\"SUM(CASE WHEN {duck_col} IS NULL THEN 1 ELSE 0 END) AS {duck_col}_nulls\"\n",
    "                         for duck_col in cols])\n",
    "sql_nulls = f\"SELECT {null_exprs} FROM imdb_merged_cleaned_duckdb.parquet;\"\n",
    "null_counts = con.execute(sql_nulls).fetchdf()\n",
    "# transpose for readability\n",
    "null_counts_t = null_counts.T\n",
    "null_counts_t.columns = ['null_count']\n",
    "display(null_counts_t[null_counts_t['null_count']>0].sort_values('null_count', ascending=False).head(200))\n",
    "\n",
    "# 5) percent nulls for the top offenders\n",
    "print(\"\\nTop 30 percent missing (approx):\")\n",
    "total = con.execute(\"SELECT COUNT(*) FROM imdb_merged_cleaned_duckdb.parquet\").fetchone()[0]\n",
    "pct_rows = []\n",
    "for c in cols:\n",
    "    nulls = con.execute(f\"SELECT SUM(CASE WHEN {c} IS NULL THEN 1 ELSE 0 END) FROM imdb_merged_cleaned_duckdb.parquet\").fetchone()[0]\n",
    "    pct = (nulls / total * 100) if total>0 else 0\n",
    "    pct_rows.append((c, nulls, pct))\n",
    "pct_rows = sorted(pct_rows, key=lambda x: x[1], reverse=True)\n",
    "for c, nulls, pct in pct_rows[:30]:\n",
    "    print(f\"{c:30s} | nulls={nulls:10d} | pct={pct:6.3f}%\")\n",
    "\n",
    "# 6) Show non-castable examples for numeric columns (common cause of unexpected nulls)\n",
    "NUMERIC_CHECK = ['averageRating','numVotes','runtimeMinutes','startYear']\n",
    "for c in NUMERIC_CHECK:\n",
    "    if c in cols:\n",
    "        q = f\"SELECT {c} FROM imdb_merged_cleaned_duckdb.parquet WHERE {c} IS NOT NULL AND TRY_CAST({c} AS DOUBLE) IS NULL LIMIT 50;\"\n",
    "        sample_bad = con.execute(q).fetchdf()\n",
    "        print(f\"\\nNon-castable examples for {c} (up to 50 rows):\")\n",
    "        display(sample_bad)\n",
    "\n",
    "# 7) Show rows that contain literal '\\N' for string columns (common issue)\n",
    "STRING_CHECK = ['primaryTitle','primaryName','title','region','language','genres','directors','writers']\n",
    "for c in STRING_CHECK:\n",
    "    if c in cols:\n",
    "        q = f\"SELECT {c}, COUNT(*) as cnt FROM imdb_merged_cleaned_duckdb.parquet WHERE {c} = '\\\\\\\\N' GROUP BY {c} LIMIT 10;\"\n",
    "        res = con.execute(q).fetchall()\n",
    "        if res:\n",
    "            print(f\"\\nLiteral '\\\\N' occurrences in column {c}:\")\n",
    "            print(res)\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dd3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# The URL to your cleaned file\n",
    "url = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-26_112727_UTC/imdb_merged_cleaned_duckdb.parquet\"\n",
    "\n",
    "# Connect to an in-memory database\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "# 1. Install and load the httpfs extension\n",
    "# This is required to read files from URLs\n",
    "print(\"Loading httpfs extension...\")\n",
    "con.execute(\"INSTALL httpfs;\")\n",
    "con.execute(\"LOAD httpfs;\")\n",
    "\n",
    "# 2. Create a VIEW (this is instant and uses no memory)\n",
    "# This just tells DuckDB where the file is. It doesn't download it.\n",
    "print(f\"Registering URL as 'imdb_cleaned' view...\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW imdb_cleaned AS SELECT * FROM '{url}'\")\n",
    "\n",
    "print(\"\\n✅ Done! The view 'imdb_cleaned' is ready to be queried.\")\n",
    "\n",
    "# ==========================================================\n",
    "#  NOW YOU CAN QUERY IT SAFELY:\n",
    "# ==========================================================\n",
    "\n",
    "# Example 1: Get 10 rows to see the columns\n",
    "print(\"\\n--- Example 1: Grabbing 10 rows ---\")\n",
    "df_sample = con.sql(\"SELECT * FROM imdb_cleaned LIMIT 10\").df()\n",
    "print(df_sample)\n",
    "\n",
    "\n",
    "# Example 2: Run an aggregation\n",
    "# DuckDB does the heavy work, you just get the small result.\n",
    "print(\"\\n--- Example 2: Running a safe aggregation ---\")\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    titleType, \n",
    "    COUNT(*) as total_rows\n",
    "FROM imdb_cleaned \n",
    "GROUP BY titleType\n",
    "\"\"\"\n",
    "df_agg = con.sql(query).df()\n",
    "\n",
    "print(df_agg)\n",
    "\n",
    "# You can keep using 'con' to run any query you want on the 'imdb_cleaned' view\n",
    "# con.close() # Close it when you're all done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5852242",
   "metadata": {},
   "source": [
    "# Checking how our cleaned data looks like on a sample cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a2fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       tconst  titleType          primaryTitle       originalTitle  isAdult  \\\n",
      "0   tt0207871   tvSeries             buccaneer           Buccaneer      0.0   \n",
      "1   tt0118694      movie  in the mood for love    Fa yeung nin wah      0.0   \n",
      "2  tt13586826  tvEpisode    allumer le camping  Allumer le Camping      0.0   \n",
      "3   tt2226407      movie         the landlords     Padroni di casa      0.0   \n",
      "4  tt28636869  tvEpisode          episode #2.4        Episode #2.4      0.0   \n",
      "\n",
      "   startYear endYear  runtimeMinutes                  genres  averageRating  \\\n",
      "0     1980.0    None            50.0         adventure,drama            6.8   \n",
      "1     2000.0    None            98.0           drama,romance            8.0   \n",
      "2     2020.0    None            45.0                  comedy            5.4   \n",
      "3     2012.0    None            90.0                   drama            6.2   \n",
      "4     2023.0    None             NaN  action,adventure,drama            8.0   \n",
      "\n",
      "   ...  ordering_1     nconst  category                characters   nconst_1  \\\n",
      "0  ...        10.0  nm0204096     actor              [accountant]  nm0204096   \n",
      "1  ...         1.0  nm0001041   actress  [su li-zhen - mrs. chan]  nm0001041   \n",
      "2  ...         5.0  nm7032070   actress            [audrey dukor]  nm7032070   \n",
      "3  ...        19.0  nm1600173  composer                            nm1600173   \n",
      "4  ...         1.0  nm0453640     actor              [jin ho-gae]  nm0453640   \n",
      "\n",
      "        primaryName birthYear  deathYear                   primaryProfession  \\\n",
      "0   geoffrey davion    1940.0     1996.0                               actor   \n",
      "1     maggie cheung    1964.0        NaN  actress,soundtrack,archive_footage   \n",
      "2           candiie       NaN        NaN                      actress,writer   \n",
      "3  cesare cremonini    1980.0        NaN               composer,actor,writer   \n",
      "4       kim rae-won    1981.0        NaN                               actor   \n",
      "\n",
      "                              knownForTitles  \n",
      "0    tt0087749,tt0072566,tt0090852,tt0065290  \n",
      "1    tt0118694,tt0299977,tt0101258,tt0117905  \n",
      "2  tt0832440,tt15710992,tt11502554,tt8304664  \n",
      "3    tt2226407,tt2039331,tt0813681,tt0306458  \n",
      "4    tt4329922,tt0395140,tt1491379,tt0266855  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20968 entries, 0 to 20967\n",
      "Data columns (total 34 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   tconst             20968 non-null  object \n",
      " 1   titleType          20968 non-null  object \n",
      " 2   primaryTitle       20968 non-null  object \n",
      " 3   originalTitle      20968 non-null  object \n",
      " 4   isAdult            20968 non-null  float64\n",
      " 5   startYear          20966 non-null  float64\n",
      " 6   endYear            1426 non-null   object \n",
      " 7   runtimeMinutes     17571 non-null  float64\n",
      " 8   genres             20968 non-null  object \n",
      " 9   averageRating      20968 non-null  float64\n",
      " 10  numVotes           20968 non-null  float64\n",
      " 11  directors          20968 non-null  object \n",
      " 12  writers            20968 non-null  object \n",
      " 13  parentTconst       6058 non-null   object \n",
      " 14  seasonNumber       20968 non-null  float64\n",
      " 15  episodeNumber      20968 non-null  float64\n",
      " 16  titleId            20968 non-null  object \n",
      " 17  ordering           20968 non-null  float64\n",
      " 18  title              20968 non-null  object \n",
      " 19  region             20968 non-null  object \n",
      " 20  language           20968 non-null  object \n",
      " 21  types              15601 non-null  object \n",
      " 22  isOriginalTitle    20968 non-null  float64\n",
      " 23  tconst_1           20956 non-null  object \n",
      " 24  ordering_1         20956 non-null  float64\n",
      " 25  nconst             20956 non-null  object \n",
      " 26  category           20956 non-null  object \n",
      " 27  characters         20968 non-null  object \n",
      " 28  nconst_1           20954 non-null  object \n",
      " 29  primaryName        20968 non-null  object \n",
      " 30  birthYear          11762 non-null  float64\n",
      " 31  deathYear          3882 non-null   float64\n",
      " 32  primaryProfession  20579 non-null  object \n",
      " 33  knownForTitles     20936 non-null  object \n",
      "dtypes: float64(12), object(22)\n",
      "memory usage: 5.4+ MB\n",
      "\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://workspace4824871889.blob.core.windows.net/azureml-blobstore-84f516da-0fe5-4f33-8f3c-f18ec8e2b4f7/UI/2025-10-26_114928_UTC/imdb_merged_cleaned_duckdb.parquet\"\n",
    "df = pd.read_parquet(url, engine=\"pyarrow\")\n",
    "\n",
    "print(df.head())\n",
    "print('\\n', df.info())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
